{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7adnkHUo9TBz"
   },
   "source": [
    "# Fusion HyperMamba Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3022,
     "status": "ok",
     "timestamp": 1729546249413,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "a3DW2ucDRG2Z",
    "outputId": "b43f82c7-153c-4b4b-c912-9ce2adae891e"
   },
   "outputs": [],
   "source": [
    "#pip install spectral mat73  einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zudwFZMrRDDC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "from einops import rearrange\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from scipy import io\n",
    "import torch.utils.data\n",
    "import scipy.io as sio\n",
    "import mat73\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "m=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OATt9TAf90MC"
   },
   "source": [
    "# 0 Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24941,
     "status": "ok",
     "timestamp": 1729546295006,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "Vpwq4Yi-tgjs",
    "outputId": "f52cb187-c6a4-448c-aac2-09f16b4f0c63"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1729546295920,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "vMin2GFJtorP",
    "outputId": "0daa71cf-ef67-4fc8-edf8-36eafc253039"
   },
   "outputs": [],
   "source": [
    "#! ls '/content/drive/MyDrive/A02_RemoteSensingData/UHS_2013_DFTC/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4NMT_vf3t3Bg"
   },
   "outputs": [],
   "source": [
    "# # Define the path\n",
    "#path='/content/drive/MyDrive/A02_RemoteSensingData/UHS_2013_DFTC/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivt40duEwqsP"
   },
   "source": [
    "#1.0  Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B6TlJRoRw0z4"
   },
   "outputs": [],
   "source": [
    "# Configuration class\n",
    "class Config:\n",
    "    def __init__(self, in_channels, num_patches, kernel_size, patch_size, emb_size, dim, depth, heads, dim_head, mlp_ratio, num_classes, dropout, pos_emb_size, class_emb_size, stride, output_dim):  # Set default output_dim to 1\n",
    "        self.in_channels = in_channels\n",
    "        self.num_patches = num_patches\n",
    "        self.kernel_size = kernel_size\n",
    "        self.patch_size = patch_size\n",
    "        self.emb_size = emb_size\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.class_emb_size = class_emb_size\n",
    "        self.stride = stride\n",
    "        self.output_dim = output_dim  # Ensure output_dim is a part of the config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a2VjJdHwP1V"
   },
   "source": [
    "### 1.1 Full Architecture Of Forward backward Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversed along bands  Method 2\n",
    "\n",
    "class HSIVimBlock(nn.Module):\n",
    "    def __init__(self, spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init):\n",
    "        super(HSIVimBlock, self).__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.num_bands = num_bands\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LayerNorm over Bands\n",
    "        self.norm = nn.LayerNorm(num_bands)\n",
    "\n",
    "        # Adjusted linear layers to handle reversed bands\n",
    "        self.linear_x = nn.Linear(num_bands, hidden_dim)\n",
    "        self.linear_z = nn.Linear(num_bands, hidden_dim)\n",
    "\n",
    "        # Convolution for forward and backward paths\n",
    "        self.forward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.backward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "\n",
    "        # Trainable matrices and delta parameter\n",
    "        self.A = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.delta_param = nn.Parameter(torch.full((hidden_dim,), delta_param_init))\n",
    "\n",
    "        # Linear layers for final transformation\n",
    "        self.linear_forward = nn.Linear(hidden_dim, output_dim)\n",
    "        self.linear_backward = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Batch, H, W, Bands = x.shape  # Input shape: [Batch, Height, Width, Bands]\n",
    "\n",
    "        # Reverse bands for z_proj\n",
    "        x_reversed = torch.flip(x, dims=[-1])  # Reverse along the Bands dimension\n",
    "\n",
    "        # Flatten spatial dimensions for processing\n",
    "        x = x.view(Batch, H * W, Bands)  # Shape: [Batch, H*W, Bands]\n",
    "        z = x_reversed.view(Batch, H * W, Bands)  # Shape: [Batch, H*W, Bands]\n",
    "\n",
    "        # Apply LayerNorm to the Bands dimension\n",
    "        x = self.norm(x)  # Shape: [Batch, H*W, Bands]\n",
    "        z = self.norm(z)  # Shape: [Batch, H*W, Bands]\n",
    "\n",
    "        # Linear projection to hidden dimensions\n",
    "        x_proj = self.linear_x(x)  # Shape: [Batch, H*W, hidden_dim]\n",
    "        z_proj = self.linear_z(z)  # Shape: [Batch, H*W, hidden_dim]\n",
    "\n",
    "        # Reshape for Conv1d compatibility\n",
    "        x_proj = x_proj.permute(0, 2, 1)  # Shape: [Batch, hidden_dim, H*W]\n",
    "        z_proj = z_proj.permute(0, 2, 1)  # Shape: [Batch, hidden_dim, H*W]\n",
    "\n",
    "        # Reverse the spatial dimension for backward path\n",
    "        #z_proj_reversed = torch.flip(z_proj, dims=[-1])  # Reverse along the spatial dimension\n",
    "\n",
    "        # Conv1D processing\n",
    "        x_forward = F.silu(self.forward_conv1d(x_proj))\n",
    "        x_backward = F.silu(self.backward_conv1d(z_proj))\n",
    "\n",
    "        # Apply delta parameter\n",
    "        delta_expanded = self.delta_param.unsqueeze(0).unsqueeze(2)  # Shape: [1, hidden_dim, 1]\n",
    "\n",
    "        # Forward and backward SSM processing\n",
    "        forward_ssm_output = torch.tanh(\n",
    "            self.forward_conv1d(x_proj) + torch.matmul(self.A, x_proj) + delta_expanded\n",
    "        )\n",
    "        backward_ssm_output = torch.tanh(\n",
    "            self.backward_conv1d(z_proj) + torch.matmul(self.B, z_proj) + delta_expanded\n",
    "        )\n",
    "\n",
    "        # Combine forward and backward outputs\n",
    "        forward_reduced = forward_ssm_output.mean(dim=2)  # Shape: [Batch, hidden_dim]\n",
    "        backward_reduced = backward_ssm_output.mean(dim=2)  # Shape: [Batch, hidden_dim]\n",
    "\n",
    "        # Linear layers for final transformation\n",
    "        y_forward = self.linear_forward(forward_reduced)  # Shape: [Batch, output_dim]\n",
    "        y_backward = self.linear_backward(backward_reduced)  # Shape: [Batch, output_dim]\n",
    "\n",
    "        # Combine forward and backward results\n",
    "        y_combined = y_forward + y_backward  # Shape: [Batch, output_dim]\n",
    "\n",
    "        return y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZwRy8jeeXvZ8"
   },
   "outputs": [],
   "source": [
    "# # Version 2.0 This involves reversing the input tensor for the backward path before applying the backward_conv1d operation\n",
    "\n",
    "# class HSIVimBlock(nn.Module):\n",
    "#     def __init__(self, spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init):\n",
    "#         super(HSIVimBlock, self).__init__()\n",
    "#         input_dim = spatial_dim * spatial_dim * num_bands\n",
    "#         self.norm = nn.LayerNorm(input_dim)\n",
    "#         # Initialization with self.hidden_dim\n",
    "#         self.spatial_dim = spatial_dim\n",
    "#         self.num_bands = num_bands\n",
    "#         self.hidden_dim = hidden_dim\n",
    "\n",
    "#         # LayerNorm is now expecting a flattened feature vector of Bands*H*W elements\n",
    "#         self.norm = nn.LayerNorm(num_bands * spatial_dim * spatial_dim)\n",
    "\n",
    "#         # Adjust linear layers according to the new input dimension\n",
    "#         self.linear_x = nn.Linear(num_bands * spatial_dim * spatial_dim, hidden_dim)\n",
    "#         self.linear_z = nn.Linear(num_bands * spatial_dim * spatial_dim, hidden_dim)\n",
    "\n",
    "#         self.forward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "#         self.backward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "\n",
    "#         self.A = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "#         self.B = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "#         #self.C = nn.Parameter(torch.randn(output_dim, hidden_dim))\n",
    "#         self.delta_param = nn.Parameter(torch.full((hidden_dim,), delta_param_init))\n",
    "\n",
    "#         self.linear_forward = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.linear_backward = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         Batch, H, W, Bands = x.shape  # Correct shape extraction assuming [Batch, Height, Width, Bands]\n",
    "\n",
    "#         # Correctly reshape for LayerNorm to flatten all spatial and spectral information\n",
    "#         x = x.reshape(Batch, -1)  # New shape: [Batch, Bands*H*W]\n",
    "\n",
    "#         # Normalize across the flattened spatial-spectral data\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         # Projection to hidden dimensions\n",
    "#         x_proj = self.linear_x(x)\n",
    "#         z_proj = self.linear_z(x)\n",
    "\n",
    "#         # Ensure correct reshaping for Conv1d compatibility\n",
    "#         x_proj = x_proj.view(Batch, self.hidden_dim, -1)\n",
    "#         z_proj = z_proj.view(Batch, self.hidden_dim, -1)\n",
    "\n",
    "#         # Reverse z_proj for the backward path\n",
    "#         z_proj_reversed = torch.flip(z_proj, dims=[-1])\n",
    "\n",
    "#         # Bidirectional Conv1d processing using reversed input for the backward path\n",
    "#         x_forward = F.silu(self.forward_conv1d(x_proj))\n",
    "#         x_backward = F.silu(self.backward_conv1d(z_proj_reversed))\n",
    "\n",
    "#         # Apply delta parameter correctly\n",
    "#         delta_expanded = self.delta_param.unsqueeze(0).unsqueeze(2)  # Correct shape for broadcasting\n",
    "\n",
    "#         # SSM processing with delta applied, using the original and reversed inputs for forward and backward paths respectively\n",
    "#         forward_ssm_output = torch.tanh(self.forward_conv1d(x_proj) + self.A * delta_expanded)\n",
    "#         backward_ssm_output = torch.tanh(self.backward_conv1d(z_proj_reversed) + self.B * delta_expanded)\n",
    "\n",
    "#         # Combine forward and backward outputs into a single representation\n",
    "#         forward_reduced = forward_ssm_output.mean(dim=2)\n",
    "#         backward_reduced = backward_ssm_output.mean(dim=2)\n",
    "\n",
    "#         # Combine the reduced forward and backward paths\n",
    "#         y_forward = self.linear_forward(forward_reduced)\n",
    "#         y_backward = self.linear_backward(backward_reduced)\n",
    "\n",
    "#         # Element-wise sum of forward and backward outputs\n",
    "#         y_combined = y_forward + y_backward\n",
    "\n",
    "#         # Return the combined output\n",
    "#         return y_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZnKBx3C9lG0"
   },
   "source": [
    "### 1.2 SpatialFeature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "02uU_S6M3EQf"
   },
   "outputs": [],
   "source": [
    "# New version\n",
    "class SpatialFeatureProcessing(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(SpatialFeatureProcessing, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First convolutional layer with dilation rate of 1 (standard convolution)\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=256, kernel_size=(3, 3), padding=1, dilation=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # Second convolutional layer with a higher dilation rate to increase the receptive field\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3), padding=2, dilation=2),  # Note the increased padding to maintain the spatial dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Adding global average pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)  # Apply global average pooling\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten all dimensions except batch\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIN7Jlj59qI0"
   },
   "source": [
    "### 1.3 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DCVCyDOHf0ol"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features=1024, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layers(x)\n",
    "        # Remove softmax here if you're using a loss function that includes it, such as nn.CrossEntropyLoss\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-iDoAegAj8D"
   },
   "source": [
    "# 1.4 Integrated into Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSIClassificationMambaModel(nn.Module):\n",
    "    def __init__(self, spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init, num_classes):\n",
    "        super(HSIClassificationMambaModel, self).__init__()\n",
    "        self.vim_block = HSIVimBlock(spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init)\n",
    "        self.output_dim = output_dim  # Save output_dim as an attribute of the class\n",
    "\n",
    "        # Initialize SpatialFeatureProcessing and Classifier here\n",
    "        # Adjusted to pass 'output_dim' as 'input_channels' to SpatialFeatureProcessing\n",
    "        self.spatial_processing = SpatialFeatureProcessing(input_channels=output_dim)\n",
    "        # Assuming the output of SpatialFeatureProcessing matches the in_features expected by Classifier\n",
    "        self.classifier = Classifier(in_features=512, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vim_block(x)\n",
    "        # This is a placeholder. Actual reshaping depends on the output of HSIVimBlock and the input expectation of SpatialFeatureProcessing\n",
    "        x = x.view(-1, self.output_dim, 1, 1)  # Reshape to include spatial dimensions if needed\n",
    "        x = self.spatial_processing(x)\n",
    "\n",
    "        # Flatten the output from spatial processing if it's not already flat\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YPTp6kBEwgr"
   },
   "source": [
    "# Instance the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1716845917956,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "pjaOisQ-e9vP",
    "outputId": "14ff2763-5c44-4640-8888-b9926cea4065"
   },
   "outputs": [],
   "source": [
    "# # At The Middel Stage\n",
    "# # Instantiate the model\n",
    "# model = HSILidClassificationMambaModel(\n",
    "#     spatial_dim=7,\n",
    "#     hsi_num_bands=63,\n",
    "#     lidar_num_bands=1,\n",
    "#     hidden_dim=512,\n",
    "#     output_dim=256,\n",
    "#     delta_param_init=0.01,\n",
    "#     num_classes=20\n",
    "# )\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7hfU1LYg_PW"
   },
   "source": [
    "#3  Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1716845322054,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "ceR1uP-X1pvx",
    "outputId": "0f4be107-b9f5-4bec-d1a2-b9c69dec83f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'class_name': 'Healthy grass', 'training_sample': 198, 'test_sample': 1053, 'total_samples': 1251}, 2: {'class_name': 'Stressed grass', 'training_sample': 190, 'test_sample': 1064, 'total_samples': 1254}, 3: {'class_name': 'Synthetic grass', 'training_sample': 192, 'test_sample': 505, 'total_samples': 697}, 4: {'class_name': 'Trees', 'training_sample': 188, 'test_sample': 1058, 'total_samples': 1244}, 5: {'class_name': 'Soil', 'training_sample': 186, 'test_sample': 1056, 'total_samples': 1242}, 6: {'class_name': 'Water', 'training_sample': 182, 'test_sample': 141, 'total_samples': 325}, 7: {'class_name': 'Residential', 'training_sample': 196, 'test_sample': 1072, 'total_samples': 1268}, 8: {'class_name': 'Commercial', 'training_sample': 191, 'test_sample': 1053, 'total_samples': 1244}, 9: {'class_name': 'Road', 'training_sample': 193, 'test_sample': 1059, 'total_samples': 1252}, 10: {'class_name': 'Highway', 'training_sample': 191, 'test_sample': 1036, 'total_samples': 1227}, 11: {'class_name': 'Railway', 'training_sample': 181, 'test_sample': 1054, 'total_samples': 1235}, 12: {'class_name': 'Parking lot 1', 'training_sample': 192, 'test_sample': 1041, 'total_samples': 1233}, 13: {'class_name': 'Parking lot 2', 'training_sample': 184, 'test_sample': 285, 'total_samples': 469}, 14: {'class_name': 'Tennis court', 'training_sample': 181, 'test_sample': 247, 'total_samples': 428}, 15: {'class_name': 'Running track', 'training_sample': 187, 'test_sample': 473, 'total_samples': 660}}\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Define the class information\n",
    "class_info = [(1, \"Healthy grass\", 'training_sample', 198, 'test_sample', 1053,  'total', 1251),\n",
    "    (2, \"Stressed grass\",'training_sample', 190, 'test_sample', 1064,  'total', 1254),\n",
    "    (3, \"Synthetic grass\", 'training_sample', 192, 'test_sample', 505,  'total', 697),\n",
    "    (4, \"Trees\", 'training_sample', 188, 'test_sample', 1058,  'total', 1244),\n",
    "    (5, \"Soil\",'training_sample', 186, 'test_sample', 1056,  'total', 1242),\n",
    "    (6, \"Water\", 'training_sample', 182, 'test_sample', 141,  'total', 325),\n",
    "    (7, \"Residential\", 'training_sample', 196, 'test_sample', 1072,  'total', 1268),\n",
    "    (8, \"Commercial\", 'training_sample', 191, 'test_sample', 1053,  'total', 1244),\n",
    "    (9, \"Road\", 'training_sample', 193, 'test_sample', 1059,  'total', 1252),\n",
    "    (10, \"Highway\", 'training_sample', 191, 'test_sample', 1036,  'total', 1227),\n",
    "    (11, \"Railway\", 'training_sample', 181, 'test_sample', 1054,  'total', 1235),\n",
    "    (12, \"Parking lot 1\", 'training_sample', 192, 'test_sample', 1041,  'total', 1233),\n",
    "    (13, \"Parking lot 2\", 'training_sample', 184, 'test_sample',285,  'total', 469),\n",
    "    (14, \"Tennis court\",'training_sample', 181, 'test_sample', 247,  'total', 428),\n",
    "    (15, \"Running track\", 'training_sample', 187, 'test_sample', 473,  'total', 660)]\n",
    "\n",
    "# Create a dictionary to store class number, class name, and class samples\n",
    "class_dict = {class_number: {\"class_name\": class_name,\n",
    "                             'training_sample': training_sample,\n",
    "                             'test_sample': test_sample,\n",
    "                             \"total_samples\": total}\n",
    "              for class_number, class_name, _, training_sample, _, test_sample, _, total in class_info}\n",
    "\n",
    "print(class_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1799,
     "status": "ok",
     "timestamp": 1729547339818,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "3d23b73f",
    "outputId": "b2f860b1-3ebc-4fbb-839c-86cf3c50cb72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi_2013_data shape: (349, 1905, 144)\n",
      "Lidar_2013_data shape: (349, 1905, 1)\n",
      "gt_2013_data.shape: (349, 1905)\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Loads Data\n",
    "# Load hyperpsectral data\n",
    "hsi_2013_data=sio.loadmat('2013_IEEE_GRSS_DF_Contest_CASI_349_1905_144.mat')['ans']\n",
    "print('hsi_2013_data shape:', hsi_2013_data.shape)\n",
    "\n",
    "# Loader Lidar  data\n",
    "import mat73\n",
    "lidar_2013_data = sio.loadmat('2013_IEEE_GRSS_DF_Contest_LiDAR.mat')['LiDAR_data']\n",
    "\n",
    "print('Lidar_2013_data shape:', lidar_2013_data.shape)\n",
    "\n",
    "#Load ground truth labels\n",
    "gt_2013_data=sio.loadmat('GRSS2013.mat')['name']\n",
    "print('gt_2013_data.shape:', gt_2013_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomralisation Raw Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSI data shape: (349, 1905, 144)\n",
      "HSI normalized shape: (349, 1905, 144)\n",
      "LiDAR data shape: (349, 1905, 1)\n",
      "LiDAR normalized shape: (349, 1905, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Normalization function for HSI and LiDAR data\n",
    "def normalize_data(data, method=\"minmax\"):\n",
    "    \"\"\"\n",
    "    Normalize hyperspectral or LiDAR data.\n",
    "    \n",
    "    Args:\n",
    "        data (numpy array): Input data array (e.g., HSI or LiDAR).\n",
    "        method (str): Normalization method, \"minmax\" or \"zscore\".\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: Normalized data.\n",
    "    \"\"\"\n",
    "    if method == \"minmax\":\n",
    "        # Reshape the data for MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        flat_data = data.reshape(-1, data.shape[-1])\n",
    "        normalized_data = scaler.fit_transform(flat_data).reshape(data.shape)\n",
    "    elif method == \"zscore\":\n",
    "        # Standard normalization: zero mean, unit variance\n",
    "        scaler = StandardScaler()\n",
    "        flat_data = data.reshape(-1, data.shape[-1])\n",
    "        normalized_data = scaler.fit_transform(flat_data).reshape(data.shape)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported normalization method. Use 'minmax' or 'zscore'.\")\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "# Load hyperspectral data\n",
    "hsi_2013_data = sio.loadmat('2013_IEEE_GRSS_DF_Contest_CASI_349_1905_144.mat')['ans']\n",
    "print('HSI data shape:', hsi_2013_data.shape)\n",
    "\n",
    "# Normalize HSI data\n",
    "hsi_2013_data_normalized = normalize_data(hsi_2013_data, method=\"minmax\")\n",
    "print('HSI normalized shape:', hsi_2013_data_normalized.shape)\n",
    "\n",
    "# Load LiDAR data\n",
    "lidar_2013_data = sio.loadmat('2013_IEEE_GRSS_DF_Contest_LiDAR.mat')['LiDAR_data']\n",
    "print('LiDAR data shape:', lidar_2013_data.shape)\n",
    "\n",
    "# Normalize LiDAR data\n",
    "# Since LiDAR has a single band, we normalize over the first two dimensions only\n",
    "lidar_min = np.min(lidar_2013_data)\n",
    "lidar_max = np.max(lidar_2013_data)\n",
    "lidar_2013_data_normalized = (lidar_2013_data - lidar_min) / (lidar_max - lidar_min)\n",
    "print('LiDAR normalized shape:', lidar_2013_data_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1716846425192,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "TUkT_fg8w8uH",
    "outputId": "7182b357-ef19-49e6-8517-647fc1b649a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi_samples shape: (15029, 1, 1, 144)\n",
      "lidar_samples shape: (15029, 1, 1, 1)\n",
      "labels shape: (15029,)\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Samples Extraction\n",
    "\n",
    "# Define patch size and stride\n",
    "patch_size = m\n",
    "stride = 1\n",
    "\n",
    "# Create an empty list to store patches and labels\n",
    "hsi_samples = []\n",
    "lidar_samples = []\n",
    "labels = []\n",
    "\n",
    "# Initialize a dictionary to store class count\n",
    "class_count = {i: 0 for i in class_dict.keys()}\n",
    "\n",
    "# Function to check if all classes have the required number of samples\n",
    "def all_classes_completed(class_count, class_dict):\n",
    "    return all(class_count[class_num] == class_dict[class_num][\"total_samples\"] for class_num in class_dict.keys())\n",
    "\n",
    "while not all_classes_completed(class_count, class_dict):\n",
    "    # Loop through the ground truth data\n",
    "    for label in class_dict.keys():\n",
    "        # Get the coordinates of the ground truth pixels\n",
    "        #coords = np.argwhere((gt_2013_data == label) & (mask > 0))\n",
    "        coords = np.argwhere(gt_2013_data == label)\n",
    "\n",
    "        # Shuffle the coordinates to randomize the patch extraction\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        for coord in coords:\n",
    "            i, j = coord\n",
    "            # Calculate the patch indices\n",
    "            i_start, i_end = i - patch_size // 2, i + patch_size // 2 + 1\n",
    "            j_start, j_end = j - patch_size // 2, j + patch_size // 2 + 1\n",
    "\n",
    "            # Check if the indices are within the bounds of the HSI data\n",
    "            if i_start >= 0 and i_end <= hsi_2013_data.shape[0] and j_start >= 0 and j_end <= hsi_2013_data.shape[1]:\n",
    "                # Extract the patch\n",
    "                hsi_patch = hsi_2013_data[i_start:i_end, j_start:j_end, :]\n",
    "\n",
    "                # Extract the LiDAR patch\n",
    "                lidar_patch = lidar_2013_data[i_start:i_end, j_start:j_end, :]\n",
    "\n",
    "                # If the class count is less than the required samples\n",
    "                if class_count[label] < class_dict[label][\"total_samples\"]:\n",
    "                    # Append the patch and its label to the list\n",
    "                    hsi_samples.append(hsi_patch)\n",
    "                    lidar_samples.append(lidar_patch)\n",
    "                    labels.append(label)\n",
    "                    class_count[label] += 1\n",
    "\n",
    "                    # If all classes have the required number of samples, exit the loop\n",
    "                    if all_classes_completed(class_count, class_dict):\n",
    "                        break\n",
    "\n",
    "# Convert the list of patches and labels into arrays\n",
    "hsi_samples = np.array(hsi_samples)\n",
    "lidar_samples = np.array(lidar_samples)\n",
    "labels = np.array(labels)\n",
    "print('hsi_samples shape:', hsi_samples.shape)\n",
    "print('lidar_samples shape:', lidar_samples.shape)\n",
    "print('labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1716846452986,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "YR4vwscb1NMY",
    "outputId": "2807859b-339a-4962-bfe4-fc8047c336c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi_training_samples shape: (2832, 1, 1, 144)\n",
      "lidar_training_samples shape: (2832, 1, 1, 1)\n",
      "training_labels shape: (2832,)\n",
      "hsi_test_samples shape: (12197, 1, 1, 144)\n",
      "lidar_test_samples shape: (12197, 1, 1, 1)\n",
      "test_labels shape: (12197,)\n"
     ]
    }
   ],
   "source": [
    "# Create training_samples_dict based on class_dict\n",
    "training_samples_dict = {class_num: class_info[\"training_sample\"] for class_num, class_info in class_dict.items()}\n",
    "\n",
    "# Assuming `hsi_samples`, `lidar_samples`, and `labels` have been previously defined\n",
    "# Convert the list of patches and labels into arrays if they aren't already\n",
    "hsi_samples = np.array(hsi_samples)\n",
    "lidar_samples = np.array(lidar_samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Create lists to store training and test samples and labels\n",
    "hsi_training_samples, lidar_training_samples, training_labels = [], [], []\n",
    "hsi_test_samples, lidar_test_samples, test_labels = [], [], []\n",
    "\n",
    "# Split samples into training and test sets based on the desired number of training samples\n",
    "for label, train_samples in training_samples_dict.items():\n",
    "    # Get indices of the current class\n",
    "    class_indices = np.where(labels == label)[0]\n",
    "\n",
    "    # Randomly shuffle the indices\n",
    "    np.random.shuffle(class_indices)\n",
    "\n",
    "    # Split the indices into training and test set indices\n",
    "    train_indices = class_indices[:train_samples]\n",
    "    test_indices = class_indices[train_samples:]\n",
    "\n",
    "    # Add training samples and labels for the current class\n",
    "    hsi_training_samples.extend(hsi_samples[train_indices])\n",
    "    lidar_training_samples.extend(lidar_samples[train_indices])\n",
    "    training_labels.extend(labels[train_indices])\n",
    "\n",
    "    # Add test samples and labels for the current class\n",
    "    hsi_test_samples.extend(hsi_samples[test_indices])\n",
    "    lidar_test_samples.extend(lidar_samples[test_indices])\n",
    "    test_labels.extend(labels[test_indices])\n",
    "\n",
    "# Convert lists back to numpy arrays\n",
    "hsi_train_samples = np.array(hsi_training_samples)\n",
    "lidar_train_samples = np.array(lidar_training_samples)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "hsi_test_samples = np.array(hsi_test_samples)\n",
    "lidar_test_samples = np.array(lidar_test_samples)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Print shapes to verify\n",
    "print('hsi_training_samples shape:', hsi_train_samples.shape)\n",
    "print('lidar_training_samples shape:', lidar_train_samples.shape)\n",
    "print('training_labels shape:', training_labels.shape)\n",
    "\n",
    "print('hsi_test_samples shape:', hsi_test_samples.shape)\n",
    "print('lidar_test_samples shape:', lidar_test_samples.shape)\n",
    "print('test_labels shape:', test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined Location Train smaples , Same as Danfeng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]\n",
      "selected_hsi_train_samples  shape: (2832, 1, 1, 144)\n",
      "selected_hsi_test_sample shape: (12197, 1, 1, 144)\n",
      "selected_lidar_train shape: (2832, 1, 1, 1)\n",
      "selected_lidar_test shape: (12197, 1, 1, 1)\n",
      "selected_hsi_lidar_train_samples shape: (2832, 1, 1, 145)\n",
      "hsselected_hsi_lidar_test_samples shape: (12197, 1, 1, 145)\n",
      "X_train shape: (2832, 1, 1, 145)\n",
      "X_test shape: (12197, 1, 1, 145)\n",
      "y_train shape: (2832,)\n",
      "y_test shape: (12197,)\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of indices for the 144 bands\n",
    "full_bands = list(range(144))\n",
    "\n",
    "# Print the list of band indices\n",
    "print(\"Band Indices:\", full_bands)\n",
    "band_indices=full_bands\n",
    "\n",
    "\n",
    "# Extract the corresponding bands from the augmented training samples\n",
    "selected_hsi_train_samples = hsi_train_samples[:,:,:, band_indices]\n",
    "selected_hsi_test_samples = hsi_test_samples[:,:,:, band_indices]\n",
    "selected_lidar_train =  lidar_train_samples\n",
    "selected_lidar_test = lidar_test_samples\n",
    "print('selected_hsi_train_samples  shape:', selected_hsi_train_samples .shape)\n",
    "print('selected_hsi_test_sample shape:', selected_hsi_test_samples.shape)\n",
    "print('selected_lidar_train shape:', selected_lidar_train.shape)\n",
    "print('selected_lidar_test shape:', selected_lidar_test.shape)\n",
    "\n",
    "# #Adding LiDAR Data to Reduced bands HSI Data,concatenate the data along axis 3\n",
    "# Concatenate along axis 3 (the band/channel axis)\n",
    "selected_hsi_lidar_train_samples = np.concatenate((selected_hsi_train_samples, selected_lidar_train), axis=3)\n",
    "selected_hsi_lidar_test_samples = np.concatenate((selected_hsi_test_samples, selected_lidar_test), axis=3)\n",
    "\n",
    "# Check the shapes of the concatenated samples\n",
    "print('selected_hsi_lidar_train_samples shape:', selected_hsi_lidar_train_samples.shape)\n",
    "print('hsselected_hsi_lidar_test_samples shape:', selected_hsi_lidar_test_samples.shape)\n",
    "\n",
    "\n",
    "X_train=selected_hsi_lidar_train_samples\n",
    "X_test=selected_hsi_lidar_test_samples\n",
    "y_train=training_labels\n",
    "y_test=test_labels\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data method 2, Only HSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=selected_hsi_train_samples\n",
    "# X_test=selected_hsi_test_samples\n",
    "# y_train=training_labels\n",
    "# y_test=test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data method 3, Only HSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data method 2, Only LiDAR\n",
    "# X_train=  lidar_train_samples\n",
    "# X_test = lidar_test_samples\n",
    "# y_train=training_labels\n",
    "# y_test=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented HSI training samples shape: (16992, 1, 1, 145)\n",
      "Augmented training labels shape: (16992,)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from scipy.ndimage import rotate\n",
    "\n",
    "def augment_training_data(hsi_training_data, training_labels, rotations=[45, 90, 135], flip_up_down=True, flip_left_right=True):\n",
    "    augmented_hsi = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for hsi, label in zip(hsi_training_data, training_labels):\n",
    "        # Original data\n",
    "        augmented_hsi.append(hsi)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # Rotations\n",
    "        for angle in rotations:\n",
    "            hsi_rotated = rotate(hsi, angle, axes=(0, 1), reshape=False, mode='nearest')\n",
    "            augmented_hsi.append(hsi_rotated)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "        # Flip up-down\n",
    "        if flip_up_down:\n",
    "            hsi_flipped_ud = np.flipud(hsi)\n",
    "            augmented_hsi.append(hsi_flipped_ud)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "        # Flip left-right\n",
    "        if flip_left_right:\n",
    "            hsi_flipped_lr = np.flipud(hsi)\n",
    "            augmented_hsi.append(hsi_flipped_lr)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "    return np.array(augmented_hsi), np.array(augmented_labels)\n",
    "\n",
    "# Augmenting the training samples\n",
    "augmented_hsi_training_samples, augmented_training_labels = augment_training_data(X_train,y_train)\n",
    "\n",
    "# Print shapes to verify the augmented training data\n",
    "print('Augmented HSI training samples shape:', augmented_hsi_training_samples.shape)\n",
    "print('Augmented training labels shape:', augmented_training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15292, 1, 1, 145)\n",
      "X_val shape: (1700, 1, 1, 145)\n",
      "y_train shape: (15292,)\n",
      "y_val shape: (1700,)\n",
      "X_test shape: (12197, 1, 1, 145)\n",
      "y_test shape: (12197,)\n",
      "After standardization:\n",
      "X_train shape: (15292, 1, 1, 145)\n",
      "X_val shape: (1700, 1, 1, 145)\n",
      "X_test shape: (12197, 1, 1, 145)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the augmented training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_hsi_training_samples, augmented_training_labels, test_size=0.1, random_state=42, stratify=augmented_training_labels\n",
    ")\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "# Store the data shapes for model\n",
    "original_train_shape = X_train.shape  # (samples, height, width, channels)\n",
    "original_val_shape = X_val.shape\n",
    "original_test_shape = X_test.shape\n",
    "\n",
    "# Reshape for standardization\n",
    "X_train_reshaped = X_train.reshape(-1, original_train_shape[1]*original_train_shape[2]*original_train_shape[3])\n",
    "X_val_reshaped = X_val.reshape(-1, original_val_shape[1]*original_val_shape[2]*original_val_shape[3])\n",
    "X_test_reshaped = X_test.reshape(-1, original_test_shape[1]*original_test_shape[2]*original_test_shape[3])\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train_reshaped)\n",
    "X_val_standardized = scaler.transform(X_val_reshaped)\n",
    "X_test_standardized = scaler.transform(X_test_reshaped)\n",
    "\n",
    "# Reshape back to original 4D shape\n",
    "X_train = X_train_standardized.reshape(original_train_shape)\n",
    "X_val = X_val_standardized.reshape(original_val_shape)\n",
    "X_test = X_test_standardized.reshape(original_test_shape)\n",
    "\n",
    "# Check the reshaped arrays\n",
    "print(\"After standardization:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Convert the split datasets to tensor datasets\n",
    "train_dataset = TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train).long())\n",
    "val_dataset = TensorDataset(torch.tensor(X_val.astype(np.float32)), torch.tensor(y_val).long())\n",
    "test_dataset = TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test).long())\n",
    "\n",
    "# Create DataLoader instances for training, validation, and testing\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YKbJ8f9kYbF"
   },
   "source": [
    "# 5.0 Training Model Memeory and Time calcualtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ur8OhPMbsB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "error",
     "timestamp": 1716846591117,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "aXbOriff1G80",
    "outputId": "d5cf3b8e-1a1c-4c6d-e540-b6befe33eeea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Memory Allocated: 298.286592 MB\n",
      "Epoch [1/100], Train Loss: 0.0757, Val Loss: 0.0669\n",
      "Validation Loss Decreased(inf--->0.066889) \t Saving The Model\n",
      "Epoch [2/100], Train Loss: 0.0603, Val Loss: 0.0539\n",
      "Validation Loss Decreased(0.066889--->0.053876) \t Saving The Model\n",
      "Epoch [3/100], Train Loss: 0.0502, Val Loss: 0.0453\n",
      "Validation Loss Decreased(0.053876--->0.045324) \t Saving The Model\n",
      "Epoch [4/100], Train Loss: 0.0429, Val Loss: 0.0388\n",
      "Validation Loss Decreased(0.045324--->0.038779) \t Saving The Model\n",
      "Epoch [5/100], Train Loss: 0.0374, Val Loss: 0.0339\n",
      "Validation Loss Decreased(0.038779--->0.033885) \t Saving The Model\n",
      "Epoch [6/100], Train Loss: 0.0329, Val Loss: 0.0298\n",
      "Validation Loss Decreased(0.033885--->0.029785) \t Saving The Model\n",
      "Epoch [7/100], Train Loss: 0.0293, Val Loss: 0.0263\n",
      "Validation Loss Decreased(0.029785--->0.026324) \t Saving The Model\n",
      "Epoch [8/100], Train Loss: 0.0263, Val Loss: 0.0234\n",
      "Validation Loss Decreased(0.026324--->0.023446) \t Saving The Model\n",
      "Epoch [9/100], Train Loss: 0.0235, Val Loss: 0.0212\n",
      "Validation Loss Decreased(0.023446--->0.021169) \t Saving The Model\n",
      "Epoch [10/100], Train Loss: 0.0213, Val Loss: 0.0191\n",
      "Validation Loss Decreased(0.021169--->0.019064) \t Saving The Model\n",
      "Epoch [11/100], Train Loss: 0.0193, Val Loss: 0.0175\n",
      "Validation Loss Decreased(0.019064--->0.017459) \t Saving The Model\n",
      "Epoch [12/100], Train Loss: 0.0176, Val Loss: 0.0157\n",
      "Validation Loss Decreased(0.017459--->0.015662) \t Saving The Model\n",
      "Epoch [13/100], Train Loss: 0.0159, Val Loss: 0.0141\n",
      "Validation Loss Decreased(0.015662--->0.014078) \t Saving The Model\n",
      "Epoch [14/100], Train Loss: 0.0145, Val Loss: 0.0130\n",
      "Validation Loss Decreased(0.014078--->0.013042) \t Saving The Model\n",
      "Epoch [15/100], Train Loss: 0.0133, Val Loss: 0.0118\n",
      "Validation Loss Decreased(0.013042--->0.011757) \t Saving The Model\n",
      "Epoch [16/100], Train Loss: 0.0121, Val Loss: 0.0108\n",
      "Validation Loss Decreased(0.011757--->0.010797) \t Saving The Model\n",
      "Epoch [17/100], Train Loss: 0.0110, Val Loss: 0.0098\n",
      "Validation Loss Decreased(0.010797--->0.009789) \t Saving The Model\n",
      "Epoch [18/100], Train Loss: 0.0100, Val Loss: 0.0088\n",
      "Validation Loss Decreased(0.009789--->0.008820) \t Saving The Model\n",
      "Epoch [19/100], Train Loss: 0.0093, Val Loss: 0.0084\n",
      "Validation Loss Decreased(0.008820--->0.008374) \t Saving The Model\n",
      "Epoch [20/100], Train Loss: 0.0085, Val Loss: 0.0075\n",
      "Validation Loss Decreased(0.008374--->0.007534) \t Saving The Model\n",
      "Epoch [21/100], Train Loss: 0.0078, Val Loss: 0.0069\n",
      "Validation Loss Decreased(0.007534--->0.006922) \t Saving The Model\n",
      "Epoch [22/100], Train Loss: 0.0071, Val Loss: 0.0064\n",
      "Validation Loss Decreased(0.006922--->0.006371) \t Saving The Model\n",
      "Epoch [23/100], Train Loss: 0.0065, Val Loss: 0.0058\n",
      "Validation Loss Decreased(0.006371--->0.005801) \t Saving The Model\n",
      "Epoch [24/100], Train Loss: 0.0061, Val Loss: 0.0052\n",
      "Validation Loss Decreased(0.005801--->0.005225) \t Saving The Model\n",
      "Epoch [25/100], Train Loss: 0.0056, Val Loss: 0.0051\n",
      "Validation Loss Decreased(0.005225--->0.005056) \t Saving The Model\n",
      "Epoch [26/100], Train Loss: 0.0051, Val Loss: 0.0045\n",
      "Validation Loss Decreased(0.005056--->0.004538) \t Saving The Model\n",
      "Epoch [27/100], Train Loss: 0.0048, Val Loss: 0.0042\n",
      "Validation Loss Decreased(0.004538--->0.004166) \t Saving The Model\n",
      "Epoch [28/100], Train Loss: 0.0044, Val Loss: 0.0038\n",
      "Validation Loss Decreased(0.004166--->0.003805) \t Saving The Model\n",
      "Epoch [29/100], Train Loss: 0.0041, Val Loss: 0.0034\n",
      "Validation Loss Decreased(0.003805--->0.003441) \t Saving The Model\n",
      "Epoch [30/100], Train Loss: 0.0037, Val Loss: 0.0032\n",
      "Validation Loss Decreased(0.003441--->0.003226) \t Saving The Model\n",
      "Epoch [31/100], Train Loss: 0.0035, Val Loss: 0.0031\n",
      "Validation Loss Decreased(0.003226--->0.003063) \t Saving The Model\n",
      "Epoch [32/100], Train Loss: 0.0032, Val Loss: 0.0027\n",
      "Validation Loss Decreased(0.003063--->0.002727) \t Saving The Model\n",
      "Epoch [33/100], Train Loss: 0.0030, Val Loss: 0.0025\n",
      "Validation Loss Decreased(0.002727--->0.002492) \t Saving The Model\n",
      "Epoch [34/100], Train Loss: 0.0027, Val Loss: 0.0023\n",
      "Validation Loss Decreased(0.002492--->0.002298) \t Saving The Model\n",
      "Epoch [35/100], Train Loss: 0.0026, Val Loss: 0.0021\n",
      "Validation Loss Decreased(0.002298--->0.002103) \t Saving The Model\n",
      "Epoch [36/100], Train Loss: 0.0024, Val Loss: 0.0019\n",
      "Validation Loss Decreased(0.002103--->0.001879) \t Saving The Model\n",
      "Epoch [37/100], Train Loss: 0.0022, Val Loss: 0.0018\n",
      "Validation Loss Decreased(0.001879--->0.001802) \t Saving The Model\n",
      "Epoch [38/100], Train Loss: 0.0020, Val Loss: 0.0017\n",
      "Validation Loss Decreased(0.001802--->0.001711) \t Saving The Model\n",
      "Epoch [39/100], Train Loss: 0.0019, Val Loss: 0.0015\n",
      "Validation Loss Decreased(0.001711--->0.001542) \t Saving The Model\n",
      "Epoch [40/100], Train Loss: 0.0017, Val Loss: 0.0015\n",
      "Validation Loss Decreased(0.001542--->0.001467) \t Saving The Model\n",
      "Epoch [41/100], Train Loss: 0.0016, Val Loss: 0.0014\n",
      "Validation Loss Decreased(0.001467--->0.001403) \t Saving The Model\n",
      "Epoch [42/100], Train Loss: 0.0014, Val Loss: 0.0012\n",
      "Validation Loss Decreased(0.001403--->0.001191) \t Saving The Model\n",
      "Epoch [43/100], Train Loss: 0.0014, Val Loss: 0.0011\n",
      "Validation Loss Decreased(0.001191--->0.001063) \t Saving The Model\n",
      "Epoch [44/100], Train Loss: 0.0012, Val Loss: 0.0010\n",
      "Validation Loss Decreased(0.001063--->0.000990) \t Saving The Model\n",
      "Epoch [45/100], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Validation Loss Decreased(0.000990--->0.000843) \t Saving The Model\n",
      "Epoch [46/100], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Validation Loss Decreased(0.000843--->0.000805) \t Saving The Model\n",
      "Epoch [47/100], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Validation Loss Decreased(0.000805--->0.000802) \t Saving The Model\n",
      "Epoch [48/100], Train Loss: 0.0009, Val Loss: 0.0006\n",
      "Validation Loss Decreased(0.000802--->0.000639) \t Saving The Model\n",
      "Epoch [49/100], Train Loss: 0.0009, Val Loss: 0.0006\n",
      "Validation Loss Decreased(0.000639--->0.000594) \t Saving The Model\n",
      "Epoch [50/100], Train Loss: 0.0008, Val Loss: 0.0006\n",
      "Epoch [51/100], Train Loss: 0.0007, Val Loss: 0.0005\n",
      "Validation Loss Decreased(0.000594--->0.000531) \t Saving The Model\n",
      "Epoch [52/100], Train Loss: 0.0007, Val Loss: 0.0005\n",
      "Validation Loss Decreased(0.000531--->0.000463) \t Saving The Model\n",
      "Epoch [53/100], Train Loss: 0.0006, Val Loss: 0.0004\n",
      "Validation Loss Decreased(0.000463--->0.000403) \t Saving The Model\n",
      "Epoch [54/100], Train Loss: 0.0006, Val Loss: 0.0004\n",
      "Validation Loss Decreased(0.000403--->0.000395) \t Saving The Model\n",
      "Epoch [55/100], Train Loss: 0.0005, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000395--->0.000330) \t Saving The Model\n",
      "Epoch [56/100], Train Loss: 0.0005, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000330--->0.000319) \t Saving The Model\n",
      "Epoch [57/100], Train Loss: 0.0005, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000319--->0.000278) \t Saving The Model\n",
      "Epoch [58/100], Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000278--->0.000232) \t Saving The Model\n",
      "Epoch [59/100], Train Loss: 0.0004, Val Loss: 0.0002\n",
      "Epoch [60/100], Train Loss: 0.0004, Val Loss: 0.0003\n",
      "Epoch [61/100], Train Loss: 0.0004, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000232--->0.000193) \t Saving The Model\n",
      "Epoch [62/100], Train Loss: 0.0003, Val Loss: 0.0003\n",
      "Epoch [63/100], Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000193--->0.000158) \t Saving The Model\n",
      "Epoch [64/100], Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch [65/100], Train Loss: 0.0003, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000158--->0.000135) \t Saving The Model\n",
      "Epoch [66/100], Train Loss: 0.0003, Val Loss: 0.0001\n",
      "Epoch [67/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000135--->0.000120) \t Saving The Model\n",
      "Epoch [68/100], Train Loss: 0.0002, Val Loss: 0.0002\n",
      "Epoch [69/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Epoch [70/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000120--->0.000086) \t Saving The Model\n",
      "Epoch [71/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Epoch [72/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000086--->0.000078) \t Saving The Model\n",
      "Epoch [73/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000078--->0.000069) \t Saving The Model\n",
      "Epoch [74/100], Train Loss: 0.0001, Val Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000069--->0.000065) \t Saving The Model\n",
      "Epoch [76/100], Train Loss: 0.0002, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000065--->0.000055) \t Saving The Model\n",
      "Epoch [77/100], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000055--->0.000053) \t Saving The Model\n",
      "Epoch [78/100], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [79/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000053--->0.000047) \t Saving The Model\n",
      "Epoch [80/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000047--->0.000045) \t Saving The Model\n",
      "Epoch [81/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000045--->0.000037) \t Saving The Model\n",
      "Epoch [82/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch [83/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000037--->0.000032) \t Saving The Model\n",
      "Epoch [84/100], Train Loss: 0.0001, Val Loss: 0.0001\n",
      "Epoch [85/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch [86/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000032--->0.000028) \t Saving The Model\n",
      "Epoch [87/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000028--->0.000026) \t Saving The Model\n",
      "Epoch [88/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000026--->0.000023) \t Saving The Model\n",
      "Epoch [89/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000023--->0.000021) \t Saving The Model\n",
      "Epoch [90/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch [91/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000021--->0.000021) \t Saving The Model\n",
      "Epoch [92/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000021--->0.000020) \t Saving The Model\n",
      "Epoch [93/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000020--->0.000019) \t Saving The Model\n",
      "Epoch [94/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000019--->0.000018) \t Saving The Model\n",
      "Epoch [95/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000018--->0.000017) \t Saving The Model\n",
      "Epoch [96/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000017--->0.000017) \t Saving The Model\n",
      "Epoch [97/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch [98/100], Train Loss: 0.0001, Val Loss: 0.0000\n",
      "Epoch [99/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Validation Loss Decreased(0.000017--->0.000013) \t Saving The Model\n",
      "Epoch [100/100], Train Loss: 0.0000, Val Loss: 0.0000\n",
      "Finished training. Total training time: 321.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Before the training loop, to record the initial memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset peak memory stats at the start\n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    print(f\"Initial Memory Allocated: {initial_memory / 1e6} MB\")\n",
    "    \n",
    "# 1.0 Training Model in GPU for HSI loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#model = HSIClassificationMambaModel(\n",
    "#    spatial_dim=7, num_bands=145, hidden_dim=256, output_dim=128, delta_param_init=0.01, num_classes=15\n",
    "#)\n",
    "\n",
    "model = HSIClassificationMambaModel(\n",
    "    spatial_dim=m, num_bands=145, hidden_dim=512, output_dim=256, delta_param_init=0.01, num_classes=15\n",
    ")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "\n",
    "epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "patience = 30\n",
    "\n",
    "start_time = time.time()  # Step 2: Record the start time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move the data into device\n",
    "        optimizer.zero_grad()\n",
    "        labels -= 1\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # Move the data into device\n",
    "            outputs = model(inputs)\n",
    "            labels -= 1\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        print(f'Validation Loss Decreased({best_val_loss:.6f}--->{epoch_val_loss:.6f}) \\t Saving The Model')\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs > patience:\n",
    "        print('Early stopping!')\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        break\n",
    "\n",
    "end_time = time.time()  # Step 3: Record the end time\n",
    "total_time = end_time - start_time  # Step 4: Calculate total training time\n",
    "\n",
    "print(f'Finished training. Total training time: {total_time:.2f} seconds')  # Print the total training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "vLfbW7zl9PVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Memory Allocated During Training: 319.532032 MB\n",
      "Final Memory Allocated: 297.859072 MB\n",
      "Memory Used During Training: -0.42752 MB\n"
     ]
    }
   ],
   "source": [
    "# After the training loop, to record the final memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    # Calculate the peak memory usage during the training\n",
    "    peak_memory = torch.cuda.max_memory_allocated()\n",
    "    # Calculate the final memory usage after training\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "\n",
    " # Calculate the memory used during the training\n",
    "    memory_used = final_memory - initial_memory\n",
    "\n",
    "    # Reset memory stats for future measurements\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    print(f\"Peak Memory Allocated During Training: {peak_memory / 1e6} MB\")\n",
    "    print(f\"Final Memory Allocated: {final_memory / 1e6} MB\")\n",
    "    # Adding the new line here to show memory used\n",
    "    print(f\"Memory Used During Training: {memory_used / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-JV3z-rolSh"
   },
   "source": [
    "### Save the modle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "3pp-QYHqolSh"
   },
   "outputs": [],
   "source": [
    "# Assuming 'model' is your instance of HSIClassificationModel or any other model\n",
    "replacement_value = m\n",
    "\n",
    "# Dynamically construct the file name\n",
    "model_save_path = 'Early_fusionp$num$_UH2013_model_state_dict.pth'\n",
    "model_save_path = model_save_path.replace('$num$', str(replacement_value))\n",
    "\n",
    "# Save the model state dictionary to the updated path\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpZ1hNquolSi"
   },
   "source": [
    "### Claculte th test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "KKUHZHJpXvaO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Early_fusionp1_UH2013_model_state_dict.pth\n",
      "Overall Accuracy (OA): 0.9560\n",
      "Average Accuracy (AA): 0.9570\n",
      "Kappa Coefficient: 0.9522\n",
      "Test time: 0.95 seconds\n",
      "Class 1 Accuracy: 0.9734\n",
      "Class 2 Accuracy: 0.9803\n",
      "Class 3 Accuracy: 0.9980\n",
      "Class 4 Accuracy: 0.9896\n",
      "Class 5 Accuracy: 0.9877\n",
      "Class 6 Accuracy: 0.9930\n",
      "Class 7 Accuracy: 0.9515\n",
      "Class 8 Accuracy: 0.9554\n",
      "Class 9 Accuracy: 0.9046\n",
      "Class 10 Accuracy: 0.9624\n",
      "Class 11 Accuracy: 0.9099\n",
      "Class 12 Accuracy: 0.9260\n",
      "Class 13 Accuracy: 0.8316\n",
      "Class 14 Accuracy: 0.9960\n",
      "Class 15 Accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "#model_save_path =  'Early_fusionp$num$_trento_model_state_dict.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "#replacement_value = m  # Replace \"m\" with this number dynamically\n",
    "\n",
    "# Replace \"$m$\" with the integer value\n",
    "#model_save_path = model_save_path.replace('$num$', str(replacement_value))\n",
    "\n",
    "\n",
    "print(f'Model saved to {model_save_path}')\n",
    "\n",
    "# Load the model (make sure to initialize the model architecture first)\n",
    "model.load_state_dict(torch.load(model_save_path,weights_only=False))\n",
    "model.to(device)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Store predictions and actual labels\n",
    "predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for hsi_patches, labels in test_loader:\n",
    "        # Move data to the appropriate device\n",
    "        hsi_patches = hsi_patches.to(device)\n",
    "        labels -= 1  # Adjust labels if necessary\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(hsi_patches)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "end_time = time.time()  # End timing\n",
    "test_time = end_time - start_time  # Calculate the test time\n",
    "\n",
    "# Optionally, calculate accuracy or other metrics using predictions and actual_labels\n",
    "\n",
    "# Convert lists to NumPy arrays for easier manipulation\n",
    "predictions_array = np.array(predictions)\n",
    "actual_labels_array = np.array(actual_labels)\n",
    "\n",
    "# Overall Accuracy\n",
    "oa = accuracy_score(actual_labels_array, predictions_array)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(actual_labels_array, predictions_array)\n",
    "# Calculate per-class accuracy from the confusion matrix\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "# Average Accuracy\n",
    "aa = np.mean(class_accuracy)\n",
    "\n",
    "# Kappa Coefficient\n",
    "kappa = cohen_kappa_score(actual_labels_array, predictions_array)\n",
    "\n",
    "print(f'Overall Accuracy (OA): {oa:.4f}')\n",
    "print(f'Average Accuracy (AA): {aa:.4f}')\n",
    "print(f'Kappa Coefficient: {kappa:.4f}')\n",
    "print(f'Test time: {test_time:.2f} seconds')  # Print the test time\n",
    "\n",
    "for i, acc in enumerate(class_accuracy): print(f'Class {i+1} Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Reversed Data stream in the code Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1( HSI+Lidar) \n",
    "Finished training. Total training time: 321.00 seconds\n",
    "    Model saved to Early_fusionp1_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9560\n",
    "Average Accuracy (AA): 0.9570\n",
    "Kappa Coefficient: 0.9522\n",
    "Test time: 0.95 seconds\n",
    "Class 1 Accuracy: 0.9734\n",
    "Class 2 Accuracy: 0.9803\n",
    "Class 3 Accuracy: 0.9980\n",
    "Class 4 Accuracy: 0.9896\n",
    "Class 5 Accuracy: 0.9877\n",
    "Class 6 Accuracy: 0.9930\n",
    "Class 7 Accuracy: 0.9515\n",
    "Class 8 Accuracy: 0.9554\n",
    "Class 9 Accuracy: 0.9046\n",
    "Class 10 Accuracy: 0.9624\n",
    "Class 11 Accuracy: 0.9099\n",
    "Class 12 Accuracy: 0.9260\n",
    "Class 13 Accuracy: 0.8316\n",
    "Class 14 Accuracy: 0.9960\n",
    "Class 15 Accuracy: 0.9958\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p3( HSI+Lidar) \n",
    "Finished training. Total training time: 305.58 seconds\n",
    "Model saved to Early_fusionp3_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9954\n",
    "Average Accuracy (AA): 0.9960\n",
    "Kappa Coefficient: 0.9950\n",
    "Test time: 1.13 seconds\n",
    "Class 1 Accuracy: 0.9991\n",
    "Class 2 Accuracy: 0.9953\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9981\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9925\n",
    "Class 8 Accuracy: 0.9981\n",
    "Class 9 Accuracy: 0.9792\n",
    "Class 10 Accuracy: 0.9971\n",
    "Class 11 Accuracy: 0.9943\n",
    "Class 12 Accuracy: 0.9962\n",
    "Class 13 Accuracy: 0.9895\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p5( HSI+Lidar) \n",
    "Finished training. Total training time: 338.37 seconds\n",
    "Model saved to Early_fusionp5_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9986\n",
    "Average Accuracy (AA): 0.9989\n",
    "Kappa Coefficient: 0.9985\n",
    "Test time: 1.27 seconds\n",
    "Class 1 Accuracy: 1.0000\n",
    "Class 2 Accuracy: 0.9953\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 1.0000\n",
    "Class 8 Accuracy: 1.0000\n",
    "Class 9 Accuracy: 0.9906\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 0.9981\n",
    "Class 12 Accuracy: 1.0000\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p7( HSI+Lidar) \n",
    "Finished training. Total training time: 414.73 seconds\n",
    "    Model saved to Early_fusionp7_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9993\n",
    "Average Accuracy (AA): 0.9995\n",
    "Kappa Coefficient: 0.9993\n",
    "Test time: 1.67 seconds\n",
    "Class 1 Accuracy: 1.0000\n",
    "Class 2 Accuracy: 1.0000\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9981\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 1.0000\n",
    "Class 8 Accuracy: 1.0000\n",
    "Class 9 Accuracy: 0.9943\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 1.0000\n",
    "Class 12 Accuracy: 1.0000\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p9( HSI+Lidar) \n",
    "Finished training. Total training time: 532.42 seconds\n",
    "    Model saved to Early_fusionp9_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9989\n",
    "Average Accuracy (AA): 0.9992\n",
    "Kappa Coefficient: 0.9988\n",
    "Test time: 2.10 seconds\n",
    "Class 1 Accuracy: 0.9924\n",
    "Class 2 Accuracy: 1.0000\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9991\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 1.0000\n",
    "Class 8 Accuracy: 1.0000\n",
    "Class 9 Accuracy: 0.9962\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 1.0000\n",
    "Class 12 Accuracy: 1.0000\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p11( HSI+Lidar) \n",
    "Finished training. Total training time: 685.01 seconds\n",
    "    Model saved to Early_fusionp11_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9971\n",
    "Average Accuracy (AA): 0.9978\n",
    "Kappa Coefficient: 0.9969\n",
    "Test time: 2.58 seconds\n",
    "Class 1 Accuracy: 0.9905\n",
    "Class 2 Accuracy: 1.0000\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9916\n",
    "Class 8 Accuracy: 0.9867\n",
    "Class 9 Accuracy: 1.0000\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 1.0000\n",
    "Class 12 Accuracy: 0.9981\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p13( HSI+Lidar) \n",
    "Finished training. Total training time: 896.55 seconds\n",
    "    Model saved to Early_fusionp13_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9958\n",
    "Average Accuracy (AA): 0.9968\n",
    "Kappa Coefficient: 0.9955\n",
    "Test time: 3.30 seconds\n",
    "Class 1 Accuracy: 0.9810\n",
    "Class 2 Accuracy: 1.0000\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 1.0000\n",
    "Class 8 Accuracy: 0.9744\n",
    "Class 9 Accuracy: 1.0000\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 1.0000\n",
    "Class 12 Accuracy: 0.9962\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p15( HSI+Lidar) \n",
    "Finished training. Total training time: 1036.45 seconds\n",
    "    Model saved to Early_fusionp15_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9957\n",
    "Average Accuracy (AA): 0.9967\n",
    "Kappa Coefficient: 0.9953\n",
    "Test time: 4.30 seconds\n",
    "Class 1 Accuracy: 0.9972\n",
    "Class 2 Accuracy: 0.9897\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9935\n",
    "Class 8 Accuracy: 0.9744\n",
    "Class 9 Accuracy: 1.0000\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 1.0000\n",
    "Class 12 Accuracy: 0.9952\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p17( HSI+Lidar) \n",
    "Finished training. Total training time: 1216.32 seconds\n",
    "Model saved to Early_fusionp17_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9967\n",
    "Average Accuracy (AA): 0.9975\n",
    "Kappa Coefficient: 0.9964\n",
    "Test time: 4.90 seconds\n",
    "Class 1 Accuracy: 0.9981\n",
    "Class 2 Accuracy: 0.9915\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9934\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9907\n",
    "Class 8 Accuracy: 1.0000\n",
    "Class 9 Accuracy: 0.9906\n",
    "Class 10 Accuracy: 1.0000\n",
    "Class 11 Accuracy: 1.0000\n",
    "Class 12 Accuracy: 0.9981\n",
    "Class 13 Accuracy: 1.0000\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Code Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only LiDAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only HSI\n",
    "Model saved to Early_fusionp11_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9828\n",
    "Average Accuracy (AA): 0.9855\n",
    "Kappa Coefficient: 0.9813\n",
    "Test time: 1.59 seconds\n",
    "Class 1 Accuracy: 0.9782\n",
    "Class 2 Accuracy: 0.9981\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9972\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9701\n",
    "Class 8 Accuracy: 0.9582\n",
    "Class 9 Accuracy: 0.9518\n",
    "Class 10 Accuracy: 0.9923\n",
    "Class 11 Accuracy: 0.9867\n",
    "Class 12 Accuracy: 0.9750\n",
    "Class 13 Accuracy: 0.9754\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined Location Trainign Samples  Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model saved to Early_fusionp11_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9759\n",
    "Average Accuracy (AA): 0.9777\n",
    "Kappa Coefficient: 0.9738\n",
    "Test time: 1.63 seconds\n",
    "Class 1 Accuracy: 0.9753\n",
    "Class 2 Accuracy: 0.9944\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9991\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 0.9860\n",
    "Class 7 Accuracy: 0.9767\n",
    "Class 8 Accuracy: 0.9658\n",
    "Class 9 Accuracy: 0.9471\n",
    "Class 10 Accuracy: 0.9759\n",
    "Class 11 Accuracy: 0.9554\n",
    "Class 12 Accuracy: 0.9491\n",
    "Class 13 Accuracy: 0.9404\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Trainign samples Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 521.93 seconds\n",
    "Model saved to Early_fusionp1_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9711\n",
    "Average Accuracy (AA): 0.9740\n",
    "Kappa Coefficient: 0.9687\n",
    "Test time: 0.69 seconds\n",
    "Class 1 Accuracy: 0.9744\n",
    "Class 2 Accuracy: 0.9850\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9915\n",
    "Class 5 Accuracy: 0.9877\n",
    "Class 6 Accuracy: 0.9930\n",
    "Class 7 Accuracy: 0.9608\n",
    "Class 8 Accuracy: 0.9801\n",
    "Class 9 Accuracy: 0.9433\n",
    "Class 10 Accuracy: 0.9846\n",
    "Class 11 Accuracy: 0.9288\n",
    "Class 12 Accuracy: 0.9500\n",
    "Class 13 Accuracy: 0.9333\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 0.9979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 249.86 seconds\n",
    "Model saved to Early_fusionp3_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9875\n",
    "Average Accuracy (AA): 0.9891\n",
    "Kappa Coefficient: 0.9865\n",
    "Test time: 0.72 seconds\n",
    "Class 1 Accuracy: 1.0000\n",
    "Class 2 Accuracy: 0.9925\n",
    "Class 3 Accuracy: 0.9980\n",
    "Class 4 Accuracy: 0.9744\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9739\n",
    "Class 8 Accuracy: 0.9839\n",
    "Class 9 Accuracy: 0.9641\n",
    "Class 10 Accuracy: 0.9961\n",
    "Class 11 Accuracy: 0.9867\n",
    "Class 12 Accuracy: 0.9923\n",
    "Class 13 Accuracy: 0.9789\n",
    "Class 14 Accuracy: 0.9960\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 323.01 seconds\n",
    "Model saved to Early_fusionp5_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9930\n",
    "Average Accuracy (AA): 0.9940\n",
    "Kappa Coefficient: 0.9924\n",
    "Test time: 0.77 seconds\n",
    "Class 1 Accuracy: 1.0000\n",
    "Class 2 Accuracy: 0.9925\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9991\n",
    "Class 5 Accuracy: 0.9991\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9851\n",
    "Class 8 Accuracy: 0.9801\n",
    "Class 9 Accuracy: 0.9877\n",
    "Class 10 Accuracy: 0.9903\n",
    "Class 11 Accuracy: 0.9915\n",
    "Class 12 Accuracy: 0.9981\n",
    "Class 13 Accuracy: 0.9860\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 311.71 seconds\n",
    "Model saved to Early_fusionp7_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9899\n",
    "Average Accuracy (AA): 0.9904\n",
    "Kappa Coefficient: 0.9891\n",
    "Test time: 0.94 seconds\n",
    "Class 1 Accuracy: 0.9981\n",
    "Class 2 Accuracy: 0.9934\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9972\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9795\n",
    "Class 8 Accuracy: 0.9896\n",
    "Class 9 Accuracy: 0.9707\n",
    "Class 10 Accuracy: 0.9903\n",
    "Class 11 Accuracy: 0.9867\n",
    "Class 12 Accuracy: 0.9885\n",
    "Class 13 Accuracy: 0.9614\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 397.16 seconds\n",
    "Model saved to Early_fusionp9_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9891\n",
    "Average Accuracy (AA): 0.9909\n",
    "Kappa Coefficient: 0.9882\n",
    "Test time: 1.05 seconds\n",
    "Class 1 Accuracy: 0.9858\n",
    "Class 2 Accuracy: 0.9981\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9991\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9832\n",
    "Class 8 Accuracy: 0.9725\n",
    "Class 9 Accuracy: 0.9783\n",
    "Class 10 Accuracy: 0.9952\n",
    "Class 11 Accuracy: 0.9839\n",
    "Class 12 Accuracy: 0.9817\n",
    "Class 13 Accuracy: 0.9860\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000\n",
    "1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 304.01 seconds\n",
    "Model saved to Early_fusionp11_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9871\n",
    "Average Accuracy (AA): 0.9894\n",
    "Kappa Coefficient: 0.9860\n",
    "Test time: 1.21 seconds\n",
    "Class 1 Accuracy: 0.9839\n",
    "Class 2 Accuracy: 0.9981\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9991\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9841\n",
    "Class 8 Accuracy: 0.9715\n",
    "Class 9 Accuracy: 0.9603\n",
    "Class 10 Accuracy: 0.9923\n",
    "Class 11 Accuracy: 0.9886\n",
    "Class 12 Accuracy: 0.9769\n",
    "Class 13 Accuracy: 0.9860\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 418.69 seconds\n",
    "Model saved to Early_fusionp13_UH2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9879\n",
    "Average Accuracy (AA): 0.9891\n",
    "Kappa Coefficient: 0.9868\n",
    "Test time: 1.39 seconds\n",
    "Class 1 Accuracy: 0.9886\n",
    "Class 2 Accuracy: 0.9962\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9953\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 1.0000\n",
    "Class 7 Accuracy: 0.9841\n",
    "Class 8 Accuracy: 0.9867\n",
    "Class 9 Accuracy: 0.9906\n",
    "Class 10 Accuracy: 0.9923\n",
    "Class 11 Accuracy: 0.9611\n",
    "Class 12 Accuracy: 0.9731\n",
    "Class 13 Accuracy: 0.9684\n",
    "Class 14 Accuracy: 1.0000\n",
    "Class 15 Accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spoYFJiQgbQ7"
   },
   "source": [
    "# 5.2 Training for HSI+Lidar in Middle Features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlpOQlNKXvaN",
    "outputId": "76d7186d-ab68-4737-87b0-404bbe32d3ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Memory Allocated: 110.053888 MB\n"
     ]
    }
   ],
   "source": [
    "# Before the training loop, to record the initial memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset peak memory stats at the start\n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    print(f\"Initial Memory Allocated: {initial_memory / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl9E80OynMPS"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "model = HSILidClassificationMambaModel(\n",
    "    spatial_dim=1,\n",
    "    hsi_num_bands=144,\n",
    "    lidar_num_bands=1,\n",
    "    hidden_dim=256,\n",
    "    output_dim=128,\n",
    "    delta_param_init=0.01,\n",
    "    num_classes=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dS0yaP3dgbQ7",
    "outputId": "8e104c12-4173-4d2c-b695-21f493d29840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.4360, Val Loss: 0.9473\n",
      "Validation Loss Decreased(inf--->0.947280) \t Saving The Model\n",
      "Epoch [2/50], Train Loss: 0.8376, Val Loss: 0.7040\n",
      "Validation Loss Decreased(0.947280--->0.703954) \t Saving The Model\n",
      "Epoch [3/50], Train Loss: 0.6435, Val Loss: 0.5636\n",
      "Validation Loss Decreased(0.703954--->0.563638) \t Saving The Model\n",
      "Epoch [4/50], Train Loss: 0.5145, Val Loss: 0.4697\n",
      "Validation Loss Decreased(0.563638--->0.469653) \t Saving The Model\n",
      "Epoch [5/50], Train Loss: 0.4397, Val Loss: 0.5063\n",
      "Epoch [6/50], Train Loss: 0.3826, Val Loss: 0.3038\n",
      "Validation Loss Decreased(0.469653--->0.303772) \t Saving The Model\n",
      "Epoch [7/50], Train Loss: 0.3305, Val Loss: 0.2943\n",
      "Validation Loss Decreased(0.303772--->0.294288) \t Saving The Model\n",
      "Epoch [8/50], Train Loss: 0.2931, Val Loss: 0.2603\n",
      "Validation Loss Decreased(0.294288--->0.260300) \t Saving The Model\n",
      "Epoch [9/50], Train Loss: 0.2654, Val Loss: 0.2374\n",
      "Validation Loss Decreased(0.260300--->0.237391) \t Saving The Model\n",
      "Epoch [10/50], Train Loss: 0.2392, Val Loss: 0.2866\n",
      "Epoch [11/50], Train Loss: 0.2248, Val Loss: 0.3103\n",
      "Epoch [12/50], Train Loss: 0.2046, Val Loss: 0.4121\n",
      "Epoch [13/50], Train Loss: 0.1922, Val Loss: 0.1914\n",
      "Validation Loss Decreased(0.237391--->0.191416) \t Saving The Model\n",
      "Epoch [14/50], Train Loss: 0.1784, Val Loss: 0.1759\n",
      "Validation Loss Decreased(0.191416--->0.175931) \t Saving The Model\n",
      "Epoch [15/50], Train Loss: 0.1596, Val Loss: 0.2895\n",
      "Epoch [16/50], Train Loss: 0.1482, Val Loss: 0.1336\n",
      "Validation Loss Decreased(0.175931--->0.133553) \t Saving The Model\n",
      "Epoch [17/50], Train Loss: 0.1375, Val Loss: 0.1160\n",
      "Validation Loss Decreased(0.133553--->0.116021) \t Saving The Model\n",
      "Epoch [18/50], Train Loss: 0.1401, Val Loss: 0.1175\n",
      "Epoch [19/50], Train Loss: 0.1238, Val Loss: 0.1690\n",
      "Epoch [20/50], Train Loss: 0.1179, Val Loss: 0.3914\n",
      "Epoch [21/50], Train Loss: 0.1153, Val Loss: 0.2092\n",
      "Epoch [22/50], Train Loss: 0.1097, Val Loss: 0.4812\n",
      "Epoch [23/50], Train Loss: 0.1075, Val Loss: 0.1912\n",
      "Epoch [24/50], Train Loss: 0.0976, Val Loss: 0.0731\n",
      "Validation Loss Decreased(0.116021--->0.073091) \t Saving The Model\n",
      "Epoch [25/50], Train Loss: 0.0886, Val Loss: 0.1502\n",
      "Epoch [26/50], Train Loss: 0.0840, Val Loss: 0.1685\n",
      "Epoch [27/50], Train Loss: 0.0857, Val Loss: 0.1725\n",
      "Epoch [28/50], Train Loss: 0.0757, Val Loss: 0.1205\n",
      "Epoch [29/50], Train Loss: 0.0817, Val Loss: 0.1180\n",
      "Epoch [30/50], Train Loss: 0.0755, Val Loss: 0.1921\n",
      "Epoch [31/50], Train Loss: 0.0691, Val Loss: 0.2146\n",
      "Epoch [32/50], Train Loss: 0.0688, Val Loss: 0.0912\n",
      "Epoch [33/50], Train Loss: 0.0732, Val Loss: 0.1826\n",
      "Epoch [34/50], Train Loss: 0.0617, Val Loss: 0.0942\n",
      "Epoch [35/50], Train Loss: 0.0523, Val Loss: 0.1499\n",
      "Early stopping!\n",
      "Finished training. Total training time: 163.66 seconds\n"
     ]
    }
   ],
   "source": [
    "# 2.0 HSI+Lidar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time  # Step 1: Import the time module\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "patience = 10\n",
    "\n",
    "start_time = time.time()  # Step 2: Record the start time\n",
    "# Updated Training Loop with HSI and LiDAR data\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for (hsi_inputs, labels), (lidar_inputs, _) in zip(hsi_train_loader, Lidar_train_loader):\n",
    "        hsi_inputs = hsi_inputs.to(device)\n",
    "        lidar_inputs = lidar_inputs.to(device)\n",
    "        labels -= 1\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(hsi_inputs, lidar_inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item() * hsi_inputs.size(0)\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(hsi_train_loader.dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for (hsi_inputs, labels), (lidar_inputs, _) in zip(hsi_val_loader, Lidar_val_loader):\n",
    "            hsi_inputs = hsi_inputs.to(device)\n",
    "            lidar_inputs = lidar_inputs.to(device)\n",
    "            labels -= 1\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(hsi_inputs, lidar_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * hsi_inputs.size(0)\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(hsi_val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "    # Check if this is the best model (based on validation loss)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        print(f'Validation Loss Decreased({best_val_loss:.6f}--->{epoch_val_loss:.6f}) \\t Saving The Model')\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if no_improve_epochs > patience:\n",
    "        print('Early stopping!')\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_wts)  # Load best model weights\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "total_time = end_time - start_time  # Calculate total training time\n",
    "print(f'Finished training. Total training time: {total_time:.2f} seconds')  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSND1JW9gbQ7",
    "outputId": "6971626c-ecd5-4bbb-aae6-1bddb1a760d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Memory Allocated During Training: 159.74656 MB\n",
      "Final Memory Allocated: 118.55872 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After the training loop, to record the final memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    # Calculate the peak memory usage during the training\n",
    "    peak_memory = torch.cuda.max_memory_allocated()\n",
    "    # Calculate the final memory usage after training\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "\n",
    "    # Reset memory stats for future measurements\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    print(f\"Peak Memory Allocated During Training: {peak_memory / 1e6} MB\")\n",
    "    print(f\"Final Memory Allocated: {final_memory / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxfBuAYlgbQ8"
   },
   "outputs": [],
   "source": [
    "# Assuming 'model' is your instance of HSIClassificationModel or any other model\n",
    "# and it's been trained\n",
    "# Save the model\n",
    "model_save_path =  'mid_fusionp1_UH2013_model_state_dict.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlYLEgApgbQ8",
    "outputId": "f7be2853-e2fc-4e35-9bc4-531c39e72f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (OA): 0.9456\n",
      "Average Accuracy (AA): 0.9478\n",
      "Kappa Coefficient: 0.9410\n",
      "Test time: 1.75 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import time\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (hsi_patches, hsi_labels), (lidar_patches, _) in zip(hsi_test_loader, Lidar_test_loader):\n",
    "        hsi_patches = hsi_patches.to(device)\n",
    "        lidar_patches = lidar_patches.to(device)\n",
    "        hsi_labels -= 1\n",
    "        hsi_labels = hsi_labels.to(device)\n",
    "\n",
    "        # Forward pass using both HSI and LiDAR patches\n",
    "        outputs = model(hsi_patches, lidar_patches)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        actual_labels.extend(hsi_labels.cpu().numpy())\n",
    "\n",
    "end_time = time.time()\n",
    "test_time = end_time - start_time\n",
    "\n",
    "# Convert lists to NumPy arrays for calculation\n",
    "predictions_array = np.array(predictions)\n",
    "actual_labels_array = np.array(actual_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "oa = accuracy_score(actual_labels_array, predictions_array)\n",
    "cm = confusion_matrix(actual_labels_array, predictions_array)\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = np.mean(class_accuracy)\n",
    "kappa = cohen_kappa_score(actual_labels_array, predictions_array)\n",
    "\n",
    "print(f'Overall Accuracy (OA): {oa:.4f}')\n",
    "print(f'Average Accuracy (AA): {aa:.4f}')\n",
    "print(f'Kappa Coefficient: {kappa:.4f}')\n",
    "print(f'Test time: {test_time:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05W4WC4jWlz-",
    "outputId": "45803c31-0b36-497a-8abe-a21dd738e3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Accuracy: 0.9839\n",
      "Class 2 Accuracy: 0.9492\n",
      "Class 3 Accuracy: 0.9960\n",
      "Class 4 Accuracy: 0.9830\n",
      "Class 5 Accuracy: 0.9905\n",
      "Class 6 Accuracy: 0.9930\n",
      "Class 7 Accuracy: 0.9823\n",
      "Class 8 Accuracy: 0.9563\n",
      "Class 9 Accuracy: 0.8451\n",
      "Class 10 Accuracy: 0.9363\n",
      "Class 11 Accuracy: 0.9222\n",
      "Class 12 Accuracy: 0.8780\n",
      "Class 13 Accuracy: 0.8070\n",
      "Class 14 Accuracy: 0.9960\n",
      "Class 15 Accuracy: 0.9979\n"
     ]
    }
   ],
   "source": [
    "for i, acc in enumerate(class_accuracy): print(f'Class {i+1} Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "OcRUYiWIWlz-"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for the plot\n",
    "patch_sizes = ['P1', 'P3', 'P5', 'P7', 'P9', 'P11', 'P13', 'P15']\n",
    "trento_oa = [0.9239, 0.9878, 0.9949, 0.9939, 0.9962, 0.9972, 0.9968, 0.9950]\n",
    "houston_oa = [0.956, 0.9954, 0.9986, 0.9993, 0.9989, 0.9971, 0.9958, 0.9957]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(patch_sizes, trento_oa, marker='o', label='Trento')\n",
    "plt.plot(patch_sizes, houston_oa, marker='s', label='Houston 2013')\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "plt.xlabel('Patch Size')\n",
    "plt.ylabel('Overall Accuracy (OA)')\n",
    "plt.title('OA Performance Based on Houston 2013 and Trento Different Patch Size')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": [
    {
     "file_id": "1vdJ_og-9a0BNRBZE0hTdttrwRQPEhjSh",
     "timestamp": 1729546157083
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
