{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7adnkHUo9TBz"
   },
   "source": [
    "# Fusion HyperMamba Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2686,
     "status": "ok",
     "timestamp": 1734303023230,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "a3DW2ucDRG2Z",
    "outputId": "5f18462e-c157-47e6-9869-fd052c40173f"
   },
   "outputs": [],
   "source": [
    "#pip install spectral mat73  einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1734303044138,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "zudwFZMrRDDC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "from einops import rearrange\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from scipy import io\n",
    "import torch.utils.data\n",
    "import scipy.io as sio\n",
    "import mat73\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "m=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OATt9TAf90MC"
   },
   "source": [
    "# 0 Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19866,
     "status": "ok",
     "timestamp": 1734303067331,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "Vpwq4Yi-tgjs",
    "outputId": "5ff88ce3-ce2e-4441-c435-032ffee7813c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1734303068898,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "vMin2GFJtorP",
    "outputId": "448b7a77-3239-4974-827f-611bbb9b36c6"
   },
   "outputs": [],
   "source": [
    "#! ls '/content/drive/MyDrive/A02_RemoteSensingData/TrentoDataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734303084951,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "4NMT_vf3t3Bg"
   },
   "outputs": [],
   "source": [
    "# Define the path\n",
    "#path='/content/drive/MyDrive/A02_RemoteSensingData/TrentoDataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1734303127116,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "ywu-dZ9PhV7F",
    "outputId": "b7258413-afa0-46d4-ea8b-4c9254bd35cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 600, 63)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 Define the class information\n",
    "class_info = [\n",
    "    (1, \"Apple trees\", 129, 3905, 4034),\n",
    "    (2, \"Buildings \", 125, 2778, 2903),\n",
    "    (3, \"Ground\", 105, 374, 479),\n",
    "    (4, \"Wood\", 154, 8969, 9123),\n",
    "    (5, \"Vineyard\", 184, 10317, 10501),  # Corrected this line\n",
    "    (6, \"Roads\", 122, 3052, 3174)\n",
    "]\n",
    "\n",
    "class_dict = {class_number: {\"class_name\": class_name, \"training\": training, \"test\": test, \"samples\": samples} for class_number, class_name, training, test, samples in class_info}\n",
    "\n",
    "# for class_number, class_info in class_dict.items():\n",
    "#     print(f\"Class {class_number}: {class_info['class_name']}\")\n",
    "#     print(f\"Training Samples: {class_info['training']}\")\n",
    "#     print(f\"Test Samples: {class_info['test']}\")\n",
    "#     print(f\"Total Samples: {class_info['samples']}\")\n",
    "#     print()\n",
    "\n",
    "#print(class_dict)\n",
    "# path\n",
    "path ='/content/drive/MyDrive/A02_RemoteSensingData/TrentoDataSet/'\n",
    "# Loader HSI TR_map_2018\n",
    "trento_data=sio.loadmat('trento_data.mat')['HSI_data']\n",
    "trento_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1734303151435,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "3d23b73f",
    "outputId": "d230c7be-b831-4416-a2fb-b5580441f3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trento_lidar_data shape: (166, 600)\n",
      "trento_hsi_data shape: (166, 600, 63)\n",
      "trento_lidar_data shape: (166, 600, 1)\n",
      "trento_gt shape: (166, 600)\n"
     ]
    }
   ],
   "source": [
    "## Define the path\n",
    "#path='/content/drive/MyDrive/A02_RemoteSensingData/TrentoDataSet/'\n",
    "\n",
    "# Loader HSI TR_map_2018\n",
    "trento_data=sio.loadmat('trento_data.mat')\n",
    "\n",
    "# Extract the HSI_data and LiDAR_data arrays\n",
    "trento_hsi_data = trento_data['HSI_data']\n",
    "trento_lidar_data = trento_data['LiDAR_data']\n",
    "print('trento_lidar_data shape:', trento_lidar_data.shape)\n",
    "# Reshape the data\n",
    "trento_lidar_data = np.reshape(trento_lidar_data, (166, 600, 1))\n",
    "\n",
    "trento_gt=trento_data['ground']\n",
    "print('trento_hsi_data shape:', trento_hsi_data.shape)\n",
    "print('trento_lidar_data shape:', trento_lidar_data.shape)\n",
    "print('trento_gt shape:', trento_gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Raw Data Normalisation\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# # Normalization function for HSI and LiDAR data\n",
    "# def normalize_data(data, method=\"minmax\"):\n",
    "#     \"\"\"\n",
    "#     Normalize hyperspectral or LiDAR data.\n",
    "    \n",
    "#     Args:\n",
    "#         data (numpy array): Input data array (e.g., HSI or LiDAR).\n",
    "#         method (str): Normalization method, \"minmax\" or \"zscore\".\n",
    "    \n",
    "#     Returns:\n",
    "#         numpy array: Normalized data.\n",
    "#     \"\"\"\n",
    "#     if method == \"minmax\":\n",
    "#         # Reshape the data for MinMaxScaler\n",
    "#         scaler = MinMaxScaler()\n",
    "#         flat_data = data.reshape(-1, data.shape[-1])\n",
    "#         normalized_data = scaler.fit_transform(flat_data).reshape(data.shape)\n",
    "#     elif method == \"zscore\":\n",
    "#         # Standard normalization: zero mean, unit variance\n",
    "#         scaler = StandardScaler()\n",
    "#         flat_data = data.reshape(-1, data.shape[-1])\n",
    "#         normalized_data = scaler.fit_transform(flat_data).reshape(data.shape)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported normalization method. Use 'minmax' or 'zscore'.\")\n",
    "    \n",
    "#     return normalized_data\n",
    "\n",
    "# # Load hyperspectral data\n",
    "# trento_hsi_data = trento_data['HSI_data']\n",
    "# print('HSI data shape:', trento_hsi_data.shape)\n",
    "\n",
    "# # Normalize HSI data\n",
    "# trento_hsi_data_normalized = normalize_data(trento_hsi_data, method=\"minmax\")\n",
    "# print('HSI normalized shape:', trento_hsi_data_normalized.shape)\n",
    "\n",
    "# # Load LiDAR data\n",
    "# trento_lidar_data = trento_data['LiDAR_data']\n",
    "# print('LiDAR data shape:', trento_lidar_data.shape)\n",
    "\n",
    "# # Normalize LiDAR data\n",
    "# # Since LiDAR has a single band, we normalize over the first two dimensions only\n",
    "# lidar_min = np.min(trento_lidar_data )\n",
    "# lidar_max = np.max(trento_lidar_data )\n",
    "# trento_lidar_data_normalized = (trento_lidar_data  - lidar_min) / (lidar_max - lidar_min)\n",
    "# trento_lidar_data_normalized  = np.reshape(trento_lidar_data_normalized , (166, 600, 1))\n",
    "# print('LiDAR normalized shape:', trento_lidar_data_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "trento_hsi_data=trento_hsi_data_normalized\n",
    "trento_lidar_data=trento_lidar_data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1167,
     "status": "ok",
     "timestamp": 1734303207780,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "4TZUub1xi6Bn",
    "outputId": "a7b5ba80-2750-4442-df9d-86ab35ccc285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi_samples shape: (30214, 1, 1, 63)\n",
      "lidar_samples shape: (30214, 1, 1, 1)\n",
      "labels shape: (30214,)\n"
     ]
    }
   ],
   "source": [
    "# # Set the background class to 0\n",
    "# Define patch size and stride\n",
    "patch_size = m\n",
    "stride = 1\n",
    "\n",
    "# Create an empty list to store patches and labels\n",
    "hsi_samples = []\n",
    "lidar_samples = []\n",
    "labels = []\n",
    "\n",
    "# Initialize a dictionary to store class count\n",
    "class_count = {i: 0 for i in class_dict.keys()}\n",
    "\n",
    "# Function to check if all classes have the required number of samples\n",
    "def all_classes_completed(class_count, class_dict):\n",
    "    return all(class_count[class_num] == class_dict[class_num][\"samples\"] for class_num in class_dict.keys())\n",
    "\n",
    "while not all_classes_completed(class_count, class_dict):\n",
    "    # Loop through the ground truth data\n",
    "    for label in class_dict.keys():\n",
    "        # Get the coordinates of the ground truth pixels\n",
    "        #coords = np.argwhere((trento_gt == label) & (mask > 0))\n",
    "        coords = np.argwhere(trento_gt == label)\n",
    "\n",
    "        # Shuffle the coordinates to randomize the patch extraction\n",
    "        np.random.shuffle(coords)\n",
    "\n",
    "        for coord in coords:\n",
    "            i, j = coord\n",
    "            # Calculate the patch indices\n",
    "            i_start, i_end = i - patch_size // 2, i + patch_size // 2 + 1\n",
    "            j_start, j_end = j - patch_size // 2, j + patch_size // 2 + 1\n",
    "\n",
    "            # Check if the indices are within the bounds of the HSI data\n",
    "            if i_start >= 0 and i_end <= trento_hsi_data.shape[0] and j_start >= 0 and j_end <= trento_hsi_data.shape[1]:\n",
    "                # Extract the patch\n",
    "                hsi_patch = trento_hsi_data[i_start:i_end, j_start:j_end, :]\n",
    "\n",
    "                # Extract the LiDAR patch\n",
    "                lidar_patch = trento_lidar_data[i_start:i_end, j_start:j_end]\n",
    "\n",
    "                # If the class count is less than the required samples\n",
    "                if class_count[label] < class_dict[label][\"samples\"]:\n",
    "                    # Append the patch and its label to the list\n",
    "                    hsi_samples.append(hsi_patch)\n",
    "                    lidar_samples.append(lidar_patch)\n",
    "                    labels.append(label)\n",
    "                    class_count[label] += 1\n",
    "\n",
    "                    # If all classes have the required number of samples, exit the loop\n",
    "                    if all_classes_completed(class_count, class_dict):\n",
    "                        break\n",
    "\n",
    "# Convert the list of patches and labels into arrays\n",
    "hsi_samples = np.array(hsi_samples)\n",
    "lidar_samples = np.array(lidar_samples)\n",
    "labels = np.array(labels)\n",
    "print('hsi_samples shape:', hsi_samples.shape)\n",
    "print('lidar_samples shape:', lidar_samples.shape)\n",
    "print('labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1734304372574,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "rtsazSWrhxz-",
    "outputId": "2dca46d9-d167-4e8e-8d36-273f6d1041b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi_training_samples shape: (819, 1, 1, 63)\n",
      "lidar_training_samples shape: (819, 1, 1, 1)\n",
      "training_labels shape: (819,)\n",
      "hsi_test_samples shape: (29395, 1, 1, 63)\n",
      "lidar_test_samples shape: (29395, 1, 1, 1)\n",
      "test_labels shape: (29395,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming `hsi_samples`, `lidar_samples`, and `labels` are defined as numpy arrays\n",
    "# Assuming `training_samples_dict` is defined and contains the desired number of training samples for each label\n",
    "# Create training_samples_dict based on class_dict\n",
    "training_samples_dict = {class_num: class_info[\"training\"] for class_num, class_info in class_dict.items()}\n",
    "hsi_samples = np.array(hsi_samples)\n",
    "lidar_samples = np.array(lidar_samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Initialize arrays to hold indices for training and test sets\n",
    "train_indices = np.array([], dtype=int)\n",
    "test_indices = np.array([], dtype=int)\n",
    "\n",
    "# Split indices into training and test sets\n",
    "for label, train_samples in training_samples_dict.items():\n",
    "    # Get indices of the current class\n",
    "    class_indices = np.where(labels == label)[0]\n",
    "\n",
    "    # Randomly shuffle the indices\n",
    "    np.random.shuffle(class_indices)\n",
    "\n",
    "    # Split the indices into training and test set indices\n",
    "    train_idx = class_indices[:train_samples]\n",
    "    test_idx = class_indices[train_samples:]\n",
    "\n",
    "    # Append to the overall training and test indices\n",
    "    train_indices = np.concatenate([train_indices, train_idx])\n",
    "    test_indices = np.concatenate([test_indices, test_idx])\n",
    "\n",
    "# Use the indices to split the samples into training and test sets\n",
    "hsi_train_samples = hsi_samples[train_indices]\n",
    "lidar_train_samples = lidar_samples[train_indices]\n",
    "training_labels = labels[train_indices]\n",
    "\n",
    "hsi_test_samples = hsi_samples[test_indices]\n",
    "lidar_test_samples = lidar_samples[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Print shapes to verify\n",
    "print('hsi_training_samples shape:', hsi_train_samples.shape)\n",
    "print('lidar_training_samples shape:', lidar_train_samples.shape)\n",
    "print('training_labels shape:', training_labels.shape)\n",
    "print('hsi_test_samples shape:', hsi_test_samples.shape)\n",
    "print('lidar_test_samples shape:', lidar_test_samples.shape)\n",
    "print('test_labels shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1406,
     "status": "ok",
     "timestamp": 1734304383410,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "TYrASfYch4W0",
    "outputId": "2e59cbda-6919-4c3b-b552-818e9f5124f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
      "selected_hsi_train_samples  shape: (819, 1, 1, 63)\n",
      "selected_hsi_test_sample shape: (29395, 1, 1, 63)\n",
      "selected_lidar_train shape: (819, 1, 1, 1)\n",
      "selected_lidar_test shape: (29395, 1, 1, 1)\n",
      "selected_hsi_lidar_train_samples shape: (819, 1, 1, 64)\n",
      "hsselected_hsi_lidar_test_samples shape: (29395, 1, 1, 64)\n",
      "X_train shape: (819, 1, 1, 64)\n",
      "X_test shape: (29395, 1, 1, 64)\n",
      "y_train shape: (819,)\n",
      "y_test shape: (29395,)\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of indices for the 144 bands\n",
    "full_bands = list(range(63))\n",
    "\n",
    "# Print the list of band indices\n",
    "print(\"Band Indices:\", full_bands)\n",
    "band_indices=full_bands\n",
    "\n",
    "\n",
    "# Extract the corresponding bands from the augmented training samples\n",
    "selected_hsi_train_samples = hsi_train_samples[:,:,:, band_indices]\n",
    "selected_hsi_test_samples = hsi_test_samples[:,:,:, band_indices]\n",
    "selected_lidar_train =  lidar_train_samples\n",
    "selected_lidar_test = lidar_test_samples\n",
    "print('selected_hsi_train_samples  shape:', selected_hsi_train_samples .shape)\n",
    "print('selected_hsi_test_sample shape:', selected_hsi_test_samples.shape)\n",
    "print('selected_lidar_train shape:', selected_lidar_train.shape)\n",
    "print('selected_lidar_test shape:', selected_lidar_test.shape)\n",
    "\n",
    "# #Adding LiDAR Data to Reduced bands HSI Data,concatenate the data along axis 3\n",
    "# Concatenate along axis 3 (the band/channel axis)\n",
    "selected_hsi_lidar_train_samples = np.concatenate((selected_hsi_train_samples, selected_lidar_train), axis=3)\n",
    "selected_hsi_lidar_test_samples = np.concatenate((selected_hsi_test_samples, selected_lidar_test), axis=3)\n",
    "\n",
    "# Check the shapes of the concatenated samples\n",
    "print('selected_hsi_lidar_train_samples shape:', selected_hsi_lidar_train_samples.shape)\n",
    "print('hsselected_hsi_lidar_test_samples shape:', selected_hsi_lidar_test_samples.shape)\n",
    "\n",
    "\n",
    "X_train=selected_hsi_lidar_train_samples\n",
    "X_test=selected_hsi_lidar_test_samples\n",
    "y_train=training_labels\n",
    "y_test=test_labels\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12557,
     "status": "ok",
     "timestamp": 1734304075944,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "lPqInDBO1LU6",
    "outputId": "da761e09-47d0-485b-f9d7-dde9fbba1af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented HSI training samples shape: (4914, 1, 1, 64)\n",
      "Augmented training labels shape: (4914,)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from scipy.ndimage import rotate\n",
    "\n",
    "def augment_training_data(hsi_training_data, training_labels, rotations=[45, 90, 135], flip_up_down=True, flip_left_right=True):\n",
    "    augmented_hsi = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for hsi, label in zip(hsi_training_data, training_labels):\n",
    "        # Original data\n",
    "        augmented_hsi.append(hsi)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # Rotations\n",
    "        for angle in rotations:\n",
    "            hsi_rotated = rotate(hsi, angle, axes=(0, 1), reshape=False, mode='nearest')\n",
    "            augmented_hsi.append(hsi_rotated)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "        # Flip up-down\n",
    "        if flip_up_down:\n",
    "            hsi_flipped_ud = np.flipud(hsi)\n",
    "            augmented_hsi.append(hsi_flipped_ud)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "        # Flip left-right\n",
    "        if flip_left_right:\n",
    "            hsi_flipped_lr = np.flipud(hsi)\n",
    "            augmented_hsi.append(hsi_flipped_lr)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "    return np.array(augmented_hsi), np.array(augmented_labels)\n",
    "\n",
    "# Augmenting the training samples\n",
    "augmented_hsi_training_samples, augmented_training_labels = augment_training_data(X_train,y_train)\n",
    "\n",
    "# Print shapes to verify the augmented training data\n",
    "print('Augmented HSI training samples shape:', augmented_hsi_training_samples.shape)\n",
    "print('Augmented training labels shape:', augmented_training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4422, 1, 1, 64)\n",
      "X_val shape: (492, 1, 1, 64)\n",
      "y_train shape: (4422,)\n",
      "y_val shape: (492,)\n",
      "X_test shape: (29395, 1, 1, 64)\n",
      "y_test shape: (29395,)\n",
      "After standardization:\n",
      "X_train shape: (4422, 1, 1, 64)\n",
      "X_val shape: (492, 1, 1, 64)\n",
      "X_test shape: (29395, 1, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the augmented training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_hsi_training_samples, augmented_training_labels, test_size=0.1, random_state=42, stratify=augmented_training_labels\n",
    ")\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "# Store the data shapes for model\n",
    "original_train_shape = X_train.shape  # (samples, height, width, channels)\n",
    "original_val_shape = X_val.shape\n",
    "original_test_shape = X_test.shape\n",
    "\n",
    "# Reshape for standardization\n",
    "X_train_reshaped = X_train.reshape(-1, original_train_shape[1]*original_train_shape[2]*original_train_shape[3])\n",
    "X_val_reshaped = X_val.reshape(-1, original_val_shape[1]*original_val_shape[2]*original_val_shape[3])\n",
    "X_test_reshaped = X_test.reshape(-1, original_test_shape[1]*original_test_shape[2]*original_test_shape[3])\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train_reshaped)\n",
    "X_val_standardized = scaler.transform(X_val_reshaped)\n",
    "X_test_standardized = scaler.transform(X_test_reshaped)\n",
    "\n",
    "# Reshape back to original 4D shape\n",
    "X_train = X_train_standardized.reshape(original_train_shape)\n",
    "X_val = X_val_standardized.reshape(original_val_shape)\n",
    "X_test = X_test_standardized.reshape(original_test_shape)\n",
    "\n",
    "# Check the reshaped arrays\n",
    "print(\"After standardization:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Convert the split datasets to tensor datasets\n",
    "train_dataset = TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train).long())\n",
    "val_dataset = TensorDataset(torch.tensor(X_val.astype(np.float32)), torch.tensor(y_val).long())\n",
    "test_dataset = TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test).long())\n",
    "\n",
    "# Create DataLoader instances for training, validation, and testing\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1734303412749,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "B6TlJRoRw0z4"
   },
   "outputs": [],
   "source": [
    "# Configuration class\n",
    "class Config:\n",
    "    def __init__(self, in_channels, num_patches, kernel_size, patch_size, emb_size, dim, depth, heads, dim_head, mlp_ratio, num_classes, dropout, pos_emb_size, class_emb_size, stride, output_dim):  # Set default output_dim to 1\n",
    "        self.in_channels = in_channels\n",
    "        self.num_patches = num_patches\n",
    "        self.kernel_size = kernel_size\n",
    "        self.patch_size = patch_size\n",
    "        self.emb_size = emb_size\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.class_emb_size = class_emb_size\n",
    "        self.stride = stride\n",
    "        self.output_dim = output_dim  # Ensure output_dim is a part of the config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a2VjJdHwP1V"
   },
   "source": [
    "### 1.1 Full Architecture Of Forward backward Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversed along bands  Method 2\n",
    "\n",
    "class HSIVimBlock(nn.Module):\n",
    "    def __init__(self, spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init):\n",
    "        super(HSIVimBlock, self).__init__()\n",
    "        self.spatial_dim = spatial_dim\n",
    "        self.num_bands = num_bands\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LayerNorm over Bands\n",
    "        self.norm = nn.LayerNorm(num_bands)\n",
    "\n",
    "        # Adjusted linear layers to handle reversed bands\n",
    "        self.linear_x = nn.Linear(num_bands, hidden_dim)\n",
    "        self.linear_z = nn.Linear(num_bands, hidden_dim)\n",
    "\n",
    "        # Convolution for forward and backward paths\n",
    "        self.forward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.backward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "\n",
    "        # Trainable matrices and delta parameter\n",
    "        self.A = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.B = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.delta_param = nn.Parameter(torch.full((hidden_dim,), delta_param_init))\n",
    "\n",
    "        # Linear layers for final transformation\n",
    "        self.linear_forward = nn.Linear(hidden_dim, output_dim)\n",
    "        self.linear_backward = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Batch, H, W, Bands = x.shape  # Input shape: [Batch, Height, Width, Bands]\n",
    "\n",
    "        # Reverse bands for z_proj\n",
    "        x_reversed = torch.flip(x, dims=[-1])  # Reverse along the Bands dimension\n",
    "\n",
    "        # Flatten spatial dimensions for processing\n",
    "        x = x.view(Batch, H * W, Bands)  # Shape: [Batch, H*W, Bands]\n",
    "        z = x_reversed.view(Batch, H * W, Bands)  # Shape: [Batch, H*W, Bands]\n",
    "\n",
    "        # Apply LayerNorm to the Bands dimension\n",
    "        x = self.norm(x)  # Shape: [Batch, H*W, Bands]\n",
    "        z = self.norm(z)  # Shape: [Batch, H*W, Bands]\n",
    "\n",
    "        # Linear projection to hidden dimensions\n",
    "        x_proj = self.linear_x(x)  # Shape: [Batch, H*W, hidden_dim]\n",
    "        z_proj = self.linear_z(z)  # Shape: [Batch, H*W, hidden_dim]\n",
    "\n",
    "        # Reshape for Conv1d compatibility\n",
    "        x_proj = x_proj.permute(0, 2, 1)  # Shape: [Batch, hidden_dim, H*W]\n",
    "        z_proj = z_proj.permute(0, 2, 1)  # Shape: [Batch, hidden_dim, H*W]\n",
    "\n",
    "        # Reverse the spatial dimension for backward path\n",
    "        z_proj_reversed = torch.flip(z_proj, dims=[-1])  # Reverse along the spatial dimension\n",
    "\n",
    "        # Conv1D processing\n",
    "        x_forward = F.silu(self.forward_conv1d(x_proj))\n",
    "        x_backward = F.silu(self.backward_conv1d(z_proj_reversed))\n",
    "\n",
    "        # Apply delta parameter\n",
    "        delta_expanded = self.delta_param.unsqueeze(0).unsqueeze(2)  # Shape: [1, hidden_dim, 1]\n",
    "\n",
    "        # Forward and backward SSM processing\n",
    "        forward_ssm_output = torch.tanh(\n",
    "            self.forward_conv1d(x_proj) + torch.matmul(self.A, x_proj) + delta_expanded\n",
    "        )\n",
    "        backward_ssm_output = torch.tanh(\n",
    "            self.backward_conv1d(z_proj_reversed) + torch.matmul(self.B, z_proj_reversed) + delta_expanded\n",
    "        )\n",
    "\n",
    "        # Combine forward and backward outputs\n",
    "        forward_reduced = forward_ssm_output.mean(dim=2)  # Shape: [Batch, hidden_dim]\n",
    "        backward_reduced = backward_ssm_output.mean(dim=2)  # Shape: [Batch, hidden_dim]\n",
    "\n",
    "        # Linear layers for final transformation\n",
    "        y_forward = self.linear_forward(forward_reduced)  # Shape: [Batch, output_dim]\n",
    "        y_backward = self.linear_backward(backward_reduced)  # Shape: [Batch, output_dim]\n",
    "\n",
    "        # Combine forward and backward results\n",
    "        y_combined = y_forward + y_backward  # Shape: [Batch, output_dim]\n",
    "\n",
    "        return y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1734303430074,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "ZwRy8jeeXvZ8"
   },
   "outputs": [],
   "source": [
    "# # Version 2.0 This involves reversing the input tensor for the backward path before applying the backward_conv1d operation\n",
    "\n",
    "# class HSIVimBlock(nn.Module):\n",
    "#     def __init__(self, spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init):\n",
    "#         super(HSIVimBlock, self).__init__()\n",
    "#         input_dim = spatial_dim * spatial_dim * num_bands\n",
    "#         self.norm = nn.LayerNorm(input_dim)\n",
    "#         # Initialization with self.hidden_dim\n",
    "#         self.spatial_dim = spatial_dim\n",
    "#         self.num_bands = num_bands\n",
    "#         self.hidden_dim = hidden_dim\n",
    "\n",
    "#         # LayerNorm is now expecting a flattened feature vector of Bands*H*W elements\n",
    "#         self.norm = nn.LayerNorm(num_bands * spatial_dim * spatial_dim)\n",
    "\n",
    "#         # Adjust linear layers according to the new input dimension\n",
    "#         self.linear_x = nn.Linear(num_bands * spatial_dim * spatial_dim, hidden_dim)\n",
    "#         self.linear_z = nn.Linear(num_bands * spatial_dim * spatial_dim, hidden_dim)\n",
    "\n",
    "#         self.forward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "#         self.backward_conv1d = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "\n",
    "#         self.A = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "#         self.B = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "#         #self.C = nn.Parameter(torch.randn(output_dim, hidden_dim))\n",
    "#         self.delta_param = nn.Parameter(torch.full((hidden_dim,), delta_param_init))\n",
    "\n",
    "#         self.linear_forward = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.linear_backward = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         Batch, H, W, Bands = x.shape  # Correct shape extraction assuming [Batch, Height, Width, Bands]\n",
    "\n",
    "#         # Correctly reshape for LayerNorm to flatten all spatial and spectral information\n",
    "#         x = x.reshape(Batch, -1)  # New shape: [Batch, Bands*H*W]\n",
    "\n",
    "#         # Normalize across the flattened spatial-spectral data\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         # Projection to hidden dimensions\n",
    "#         x_proj = self.linear_x(x)\n",
    "#         z_proj = self.linear_z(x)\n",
    "\n",
    "#         # Ensure correct reshaping for Conv1d compatibility\n",
    "#         x_proj = x_proj.view(Batch, self.hidden_dim, -1)\n",
    "#         z_proj = z_proj.view(Batch, self.hidden_dim, -1)\n",
    "\n",
    "#         # Reverse z_proj for the backward path\n",
    "#         z_proj_reversed = torch.flip(z_proj, dims=[-1])\n",
    "\n",
    "#         # Bidirectional Conv1d processing using reversed input for the backward path\n",
    "#         x_forward = F.silu(self.forward_conv1d(x_proj))\n",
    "#         x_backward = F.silu(self.backward_conv1d(z_proj_reversed))\n",
    "\n",
    "#         # Apply delta parameter correctly\n",
    "#         delta_expanded = self.delta_param.unsqueeze(0).unsqueeze(2)  # Correct shape for broadcasting\n",
    "\n",
    "#         # SSM processing with delta applied, using the original and reversed inputs for forward and backward paths respectively\n",
    "#         forward_ssm_output = torch.tanh(self.forward_conv1d(x_proj) + self.A * delta_expanded)\n",
    "#         backward_ssm_output = torch.tanh(self.backward_conv1d(z_proj_reversed) + self.B * delta_expanded)\n",
    "\n",
    "#         # Combine forward and backward outputs into a single representation\n",
    "#         forward_reduced = forward_ssm_output.mean(dim=2)\n",
    "#         backward_reduced = backward_ssm_output.mean(dim=2)\n",
    "\n",
    "#         # Combine the reduced forward and backward paths\n",
    "#         y_forward = self.linear_forward(forward_reduced)\n",
    "#         y_backward = self.linear_backward(backward_reduced)\n",
    "\n",
    "#         # Element-wise sum of forward and backward outputs\n",
    "#         y_combined = y_forward + y_backward\n",
    "\n",
    "#         # Return the combined output\n",
    "#         return y_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVmPBvlBgbQu"
   },
   "source": [
    "### 1.15 Adding Forward Processing for LiDAR Only  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZnKBx3C9lG0"
   },
   "source": [
    "### 1.2 SpatialFeature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1734303466585,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "02uU_S6M3EQf"
   },
   "outputs": [],
   "source": [
    "# New version\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "class SpatialFeatureProcessing(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(SpatialFeatureProcessing, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First convolutional layer with dilation rate of 1 (standard convolution)\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=256, kernel_size=(3, 3), padding=1, dilation=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # Second convolutional layer with a higher dilation rate to increase the receptive field\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3), padding=2, dilation=2),  # Note the increased padding to maintain the spatial dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Adding global average pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)  # Apply global average pooling\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten all dimensions except batch\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIN7Jlj59qI0"
   },
   "source": [
    "### 1.3 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1734303472098,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "DCVCyDOHf0ol"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features=1024, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layers(x)\n",
    "        # Remove softmax here if you're using a loss function that includes it, such as nn.CrossEntropyLoss\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-iDoAegAj8D"
   },
   "source": [
    "# 1.4 Integrated into Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1734303476051,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "qR9HaaJMi6Bs"
   },
   "outputs": [],
   "source": [
    "class HSIClassificationMambaModel(nn.Module):\n",
    "    def __init__(self, spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init, num_classes):\n",
    "        super(HSIClassificationMambaModel, self).__init__()\n",
    "        self.vim_block = HSIVimBlock(spatial_dim, num_bands, hidden_dim, output_dim, delta_param_init)\n",
    "        self.output_dim = output_dim  # Save output_dim as an attribute of the class\n",
    "\n",
    "        # Initialize SpatialFeatureProcessing and Classifier here\n",
    "        # Adjusted to pass 'output_dim' as 'input_channels' to SpatialFeatureProcessing\n",
    "        self.spatial_processing = SpatialFeatureProcessing(input_channels=output_dim)\n",
    "        # Assuming the output of SpatialFeatureProcessing matches the in_features expected by Classifier\n",
    "        self.classifier = Classifier(in_features=512, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vim_block(x)\n",
    "        # This is a placeholder. Actual reshaping depends on the output of HSIVimBlock and the input expectation of SpatialFeatureProcessing\n",
    "        x = x.view(-1, self.output_dim, 1, 1)  # Reshape to include spatial dimensions if needed\n",
    "        x = self.spatial_processing(x)\n",
    "\n",
    "        # Flatten the output from spatial processing if it's not already flat\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIelMSGaWlz1"
   },
   "source": [
    "#    Instance the model at the early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "id": "UA4E-RIni6Bt"
   },
   "outputs": [],
   "source": [
    "# # At The MEarly Fusion Stage , Lidar as additional band\n",
    "# # Instantiate the model\n",
    "# model = HSIClassificationMambaModel(\n",
    "#     spatial_dim=3,\n",
    "#     num_bands=64,\n",
    "#     hidden_dim=512,\n",
    "#     output_dim=256,\n",
    "#     delta_param_init=0.01,\n",
    "#     num_classes=6\n",
    "# )\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YPTp6kBEwgr"
   },
   "source": [
    "# Instance the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1734303660134,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "pjaOisQ-e9vP"
   },
   "outputs": [],
   "source": [
    "# # At The Middel Stage\n",
    "# # Instantiate the model\n",
    "# model = HSILidClassificationMambaModel(\n",
    "#     spatial_dim=7,\n",
    "#     hsi_num_bands=63,\n",
    "#     lidar_num_bands=1,\n",
    "#     hidden_dim=512,\n",
    "#     output_dim=256,\n",
    "#     delta_param_init=0.01,\n",
    "#     num_classes=20\n",
    "# )\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7hfU1LYg_PW"
   },
   "source": [
    "#3  Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YKbJ8f9kYbF"
   },
   "source": [
    "# 5.0 Training Model Memeory and Time calcualtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtM-XdHTizW-"
   },
   "source": [
    "### 5.1 Training Model for complete forward and backward archtoeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFGuWfq_i6Bz",
    "outputId": "315d7b9f-fb94-46b4-d59b-fabcb75726f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Memory Allocated: 115.165696 MB\n",
      "Epoch [1/100], Train Loss: 0.0536, Val Loss: 0.0508\n",
      "Validation Loss Decreased(inf--->0.050801) \t Saving The Model\n",
      "Epoch [2/100], Train Loss: 0.0465, Val Loss: 0.0441\n",
      "Validation Loss Decreased(0.050801--->0.044137) \t Saving The Model\n",
      "Epoch [3/100], Train Loss: 0.0409, Val Loss: 0.0386\n",
      "Validation Loss Decreased(0.044137--->0.038566) \t Saving The Model\n",
      "Epoch [4/100], Train Loss: 0.0363, Val Loss: 0.0341\n",
      "Validation Loss Decreased(0.038566--->0.034132) \t Saving The Model\n",
      "Epoch [5/100], Train Loss: 0.0325, Val Loss: 0.0305\n",
      "Validation Loss Decreased(0.034132--->0.030476) \t Saving The Model\n",
      "Epoch [6/100], Train Loss: 0.0291, Val Loss: 0.0271\n",
      "Validation Loss Decreased(0.030476--->0.027126) \t Saving The Model\n",
      "Epoch [7/100], Train Loss: 0.0262, Val Loss: 0.0246\n",
      "Validation Loss Decreased(0.027126--->0.024558) \t Saving The Model\n",
      "Epoch [8/100], Train Loss: 0.0238, Val Loss: 0.0222\n",
      "Validation Loss Decreased(0.024558--->0.022248) \t Saving The Model\n",
      "Epoch [9/100], Train Loss: 0.0219, Val Loss: 0.0203\n",
      "Validation Loss Decreased(0.022248--->0.020342) \t Saving The Model\n",
      "Epoch [10/100], Train Loss: 0.0200, Val Loss: 0.0185\n",
      "Validation Loss Decreased(0.020342--->0.018508) \t Saving The Model\n",
      "Epoch [11/100], Train Loss: 0.0184, Val Loss: 0.0169\n",
      "Validation Loss Decreased(0.018508--->0.016915) \t Saving The Model\n",
      "Epoch [12/100], Train Loss: 0.0172, Val Loss: 0.0155\n",
      "Validation Loss Decreased(0.016915--->0.015488) \t Saving The Model\n",
      "Epoch [13/100], Train Loss: 0.0159, Val Loss: 0.0146\n",
      "Validation Loss Decreased(0.015488--->0.014591) \t Saving The Model\n",
      "Epoch [14/100], Train Loss: 0.0149, Val Loss: 0.0132\n",
      "Validation Loss Decreased(0.014591--->0.013188) \t Saving The Model\n",
      "Epoch [15/100], Train Loss: 0.0138, Val Loss: 0.0125\n",
      "Validation Loss Decreased(0.013188--->0.012547) \t Saving The Model\n",
      "Epoch [16/100], Train Loss: 0.0130, Val Loss: 0.0116\n",
      "Validation Loss Decreased(0.012547--->0.011624) \t Saving The Model\n",
      "Epoch [17/100], Train Loss: 0.0123, Val Loss: 0.0108\n",
      "Validation Loss Decreased(0.011624--->0.010798) \t Saving The Model\n",
      "Epoch [18/100], Train Loss: 0.0112, Val Loss: 0.0104\n",
      "Validation Loss Decreased(0.010798--->0.010362) \t Saving The Model\n",
      "Epoch [19/100], Train Loss: 0.0108, Val Loss: 0.0095\n",
      "Validation Loss Decreased(0.010362--->0.009511) \t Saving The Model\n",
      "Epoch [20/100], Train Loss: 0.0105, Val Loss: 0.0087\n",
      "Validation Loss Decreased(0.009511--->0.008720) \t Saving The Model\n",
      "Epoch [21/100], Train Loss: 0.0096, Val Loss: 0.0085\n",
      "Validation Loss Decreased(0.008720--->0.008490) \t Saving The Model\n",
      "Epoch [22/100], Train Loss: 0.0092, Val Loss: 0.0079\n",
      "Validation Loss Decreased(0.008490--->0.007919) \t Saving The Model\n",
      "Epoch [23/100], Train Loss: 0.0084, Val Loss: 0.0074\n",
      "Validation Loss Decreased(0.007919--->0.007396) \t Saving The Model\n",
      "Epoch [24/100], Train Loss: 0.0083, Val Loss: 0.0072\n",
      "Validation Loss Decreased(0.007396--->0.007165) \t Saving The Model\n",
      "Epoch [25/100], Train Loss: 0.0080, Val Loss: 0.0067\n",
      "Validation Loss Decreased(0.007165--->0.006709) \t Saving The Model\n",
      "Epoch [26/100], Train Loss: 0.0077, Val Loss: 0.0064\n",
      "Validation Loss Decreased(0.006709--->0.006429) \t Saving The Model\n",
      "Epoch [27/100], Train Loss: 0.0071, Val Loss: 0.0061\n",
      "Validation Loss Decreased(0.006429--->0.006089) \t Saving The Model\n",
      "Epoch [28/100], Train Loss: 0.0067, Val Loss: 0.0057\n",
      "Validation Loss Decreased(0.006089--->0.005701) \t Saving The Model\n",
      "Epoch [29/100], Train Loss: 0.0065, Val Loss: 0.0055\n",
      "Validation Loss Decreased(0.005701--->0.005487) \t Saving The Model\n",
      "Epoch [30/100], Train Loss: 0.0061, Val Loss: 0.0052\n",
      "Validation Loss Decreased(0.005487--->0.005211) \t Saving The Model\n",
      "Epoch [31/100], Train Loss: 0.0058, Val Loss: 0.0048\n",
      "Validation Loss Decreased(0.005211--->0.004823) \t Saving The Model\n",
      "Epoch [32/100], Train Loss: 0.0058, Val Loss: 0.0047\n",
      "Validation Loss Decreased(0.004823--->0.004664) \t Saving The Model\n",
      "Epoch [33/100], Train Loss: 0.0056, Val Loss: 0.0043\n",
      "Validation Loss Decreased(0.004664--->0.004324) \t Saving The Model\n",
      "Epoch [34/100], Train Loss: 0.0052, Val Loss: 0.0042\n",
      "Validation Loss Decreased(0.004324--->0.004247) \t Saving The Model\n",
      "Epoch [35/100], Train Loss: 0.0050, Val Loss: 0.0040\n",
      "Validation Loss Decreased(0.004247--->0.003989) \t Saving The Model\n",
      "Epoch [36/100], Train Loss: 0.0048, Val Loss: 0.0038\n",
      "Validation Loss Decreased(0.003989--->0.003788) \t Saving The Model\n",
      "Epoch [37/100], Train Loss: 0.0046, Val Loss: 0.0038\n",
      "Epoch [38/100], Train Loss: 0.0042, Val Loss: 0.0035\n",
      "Validation Loss Decreased(0.003788--->0.003510) \t Saving The Model\n",
      "Epoch [39/100], Train Loss: 0.0040, Val Loss: 0.0033\n",
      "Validation Loss Decreased(0.003510--->0.003279) \t Saving The Model\n",
      "Epoch [40/100], Train Loss: 0.0042, Val Loss: 0.0031\n",
      "Validation Loss Decreased(0.003279--->0.003079) \t Saving The Model\n",
      "Epoch [41/100], Train Loss: 0.0039, Val Loss: 0.0031\n",
      "Validation Loss Decreased(0.003079--->0.003066) \t Saving The Model\n",
      "Epoch [42/100], Train Loss: 0.0037, Val Loss: 0.0028\n",
      "Validation Loss Decreased(0.003066--->0.002812) \t Saving The Model\n",
      "Epoch [43/100], Train Loss: 0.0035, Val Loss: 0.0027\n",
      "Validation Loss Decreased(0.002812--->0.002682) \t Saving The Model\n",
      "Epoch [44/100], Train Loss: 0.0033, Val Loss: 0.0027\n",
      "Validation Loss Decreased(0.002682--->0.002656) \t Saving The Model\n",
      "Epoch [45/100], Train Loss: 0.0030, Val Loss: 0.0025\n",
      "Validation Loss Decreased(0.002656--->0.002535) \t Saving The Model\n",
      "Epoch [46/100], Train Loss: 0.0030, Val Loss: 0.0023\n",
      "Validation Loss Decreased(0.002535--->0.002333) \t Saving The Model\n",
      "Epoch [47/100], Train Loss: 0.0029, Val Loss: 0.0023\n",
      "Validation Loss Decreased(0.002333--->0.002295) \t Saving The Model\n",
      "Epoch [48/100], Train Loss: 0.0028, Val Loss: 0.0022\n",
      "Validation Loss Decreased(0.002295--->0.002193) \t Saving The Model\n",
      "Epoch [49/100], Train Loss: 0.0027, Val Loss: 0.0019\n",
      "Validation Loss Decreased(0.002193--->0.001938) \t Saving The Model\n",
      "Epoch [50/100], Train Loss: 0.0026, Val Loss: 0.0019\n",
      "Epoch [51/100], Train Loss: 0.0024, Val Loss: 0.0019\n",
      "Validation Loss Decreased(0.001938--->0.001870) \t Saving The Model\n",
      "Epoch [52/100], Train Loss: 0.0022, Val Loss: 0.0018\n",
      "Validation Loss Decreased(0.001870--->0.001762) \t Saving The Model\n",
      "Epoch [53/100], Train Loss: 0.0023, Val Loss: 0.0016\n",
      "Validation Loss Decreased(0.001762--->0.001633) \t Saving The Model\n",
      "Epoch [54/100], Train Loss: 0.0024, Val Loss: 0.0016\n",
      "Validation Loss Decreased(0.001633--->0.001604) \t Saving The Model\n",
      "Epoch [55/100], Train Loss: 0.0022, Val Loss: 0.0015\n",
      "Validation Loss Decreased(0.001604--->0.001458) \t Saving The Model\n",
      "Epoch [56/100], Train Loss: 0.0019, Val Loss: 0.0014\n",
      "Validation Loss Decreased(0.001458--->0.001378) \t Saving The Model\n",
      "Epoch [57/100], Train Loss: 0.0018, Val Loss: 0.0014\n",
      "Epoch [58/100], Train Loss: 0.0018, Val Loss: 0.0013\n",
      "Validation Loss Decreased(0.001378--->0.001326) \t Saving The Model\n",
      "Epoch [59/100], Train Loss: 0.0018, Val Loss: 0.0014\n",
      "Epoch [60/100], Train Loss: 0.0017, Val Loss: 0.0011\n",
      "Validation Loss Decreased(0.001326--->0.001125) \t Saving The Model\n",
      "Epoch [61/100], Train Loss: 0.0015, Val Loss: 0.0012\n",
      "Epoch [62/100], Train Loss: 0.0015, Val Loss: 0.0011\n",
      "Validation Loss Decreased(0.001125--->0.001083) \t Saving The Model\n",
      "Epoch [63/100], Train Loss: 0.0015, Val Loss: 0.0009\n",
      "Validation Loss Decreased(0.001083--->0.000921) \t Saving The Model\n",
      "Epoch [64/100], Train Loss: 0.0014, Val Loss: 0.0009\n",
      "Validation Loss Decreased(0.000921--->0.000883) \t Saving The Model\n",
      "Epoch [65/100], Train Loss: 0.0013, Val Loss: 0.0008\n",
      "Validation Loss Decreased(0.000883--->0.000830) \t Saving The Model\n",
      "Epoch [66/100], Train Loss: 0.0013, Val Loss: 0.0008\n",
      "Validation Loss Decreased(0.000830--->0.000820) \t Saving The Model\n",
      "Epoch [67/100], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Validation Loss Decreased(0.000820--->0.000730) \t Saving The Model\n",
      "Epoch [68/100], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Epoch [69/100], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Validation Loss Decreased(0.000730--->0.000666) \t Saving The Model\n",
      "Epoch [70/100], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Validation Loss Decreased(0.000666--->0.000644) \t Saving The Model\n",
      "Epoch [71/100], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [72/100], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [73/100], Train Loss: 0.0009, Val Loss: 0.0005\n",
      "Validation Loss Decreased(0.000644--->0.000539) \t Saving The Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Train Loss: 0.0009, Val Loss: 0.0006\n",
      "Epoch [75/100], Train Loss: 0.0011, Val Loss: 0.0005\n",
      "Validation Loss Decreased(0.000539--->0.000477) \t Saving The Model\n",
      "Epoch [76/100], Train Loss: 0.0009, Val Loss: 0.0004\n",
      "Validation Loss Decreased(0.000477--->0.000434) \t Saving The Model\n",
      "Epoch [77/100], Train Loss: 0.0008, Val Loss: 0.0005\n",
      "Epoch [78/100], Train Loss: 0.0008, Val Loss: 0.0004\n",
      "Validation Loss Decreased(0.000434--->0.000418) \t Saving The Model\n",
      "Epoch [79/100], Train Loss: 0.0008, Val Loss: 0.0004\n",
      "Validation Loss Decreased(0.000418--->0.000406) \t Saving The Model\n",
      "Epoch [80/100], Train Loss: 0.0008, Val Loss: 0.0004\n",
      "Epoch [81/100], Train Loss: 0.0007, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000406--->0.000348) \t Saving The Model\n",
      "Epoch [82/100], Train Loss: 0.0007, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000348--->0.000338) \t Saving The Model\n",
      "Epoch [83/100], Train Loss: 0.0006, Val Loss: 0.0004\n",
      "Epoch [84/100], Train Loss: 0.0006, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000338--->0.000302) \t Saving The Model\n",
      "Epoch [85/100], Train Loss: 0.0005, Val Loss: 0.0003\n",
      "Epoch [86/100], Train Loss: 0.0006, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000302--->0.000285) \t Saving The Model\n",
      "Epoch [87/100], Train Loss: 0.0006, Val Loss: 0.0003\n",
      "Validation Loss Decreased(0.000285--->0.000252) \t Saving The Model\n",
      "Epoch [88/100], Train Loss: 0.0005, Val Loss: 0.0003\n",
      "Epoch [89/100], Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000252--->0.000237) \t Saving The Model\n",
      "Epoch [90/100], Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Epoch [91/100], Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Epoch [92/100], Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000237--->0.000210) \t Saving The Model\n",
      "Epoch [93/100], Train Loss: 0.0004, Val Loss: 0.0002\n",
      "Epoch [94/100], Train Loss: 0.0005, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000210--->0.000199) \t Saving The Model\n",
      "Epoch [95/100], Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch [96/100], Train Loss: 0.0004, Val Loss: 0.0002\n",
      "Validation Loss Decreased(0.000199--->0.000174) \t Saving The Model\n",
      "Epoch [97/100], Train Loss: 0.0004, Val Loss: 0.0002\n",
      "Epoch [98/100], Train Loss: 0.0003, Val Loss: 0.0002\n",
      "Epoch [99/100], Train Loss: 0.0004, Val Loss: 0.0001\n",
      "Validation Loss Decreased(0.000174--->0.000132) \t Saving The Model\n",
      "Epoch [100/100], Train Loss: 0.0004, Val Loss: 0.0001\n",
      "Finished training. Total training time: 67.36 seconds\n"
     ]
    }
   ],
   "source": [
    "# Before the training loop, to record the initial memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset peak memory stats at the start\n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    print(f\"Initial Memory Allocated: {initial_memory / 1e6} MB\")\n",
    "\n",
    "\n",
    "# 1.0 Training Model in GPU for HSI loader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#model = HSIClassificationMambaModel(\n",
    "#    spatial_dim=7, num_bands=145, hidden_dim=256, output_dim=128, delta_param_init=0.01, num_classes=15\n",
    "#)\n",
    "\n",
    "model = HSIClassificationMambaModel(\n",
    "    spatial_dim=m, num_bands=64, hidden_dim=512, output_dim=256, delta_param_init=0.01, num_classes=6\n",
    ")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "\n",
    "epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "patience = 30\n",
    "\n",
    "start_time = time.time()  # Step 2: Record the start time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # Move the data into device\n",
    "        optimizer.zero_grad()\n",
    "        labels -= 1\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # Move the data into device\n",
    "            outputs = model(inputs)\n",
    "            labels -= 1\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        print(f'Validation Loss Decreased({best_val_loss:.6f}--->{epoch_val_loss:.6f}) \\t Saving The Model')\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs > patience:\n",
    "        print('Early stopping!')\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        break\n",
    "\n",
    "end_time = time.time()  # Step 3: Record the end time\n",
    "total_time = end_time - start_time  # Step 4: Calculate total training time\n",
    "\n",
    "print(f'Finished training. Total training time: {total_time:.2f} seconds')  # Print the total training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "id": "n5mKHZ5si6Bz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Memory Allocated During Training: 137.745408 MB\n",
      "Final Memory Allocated: 118.025216 MB\n",
      "Memory Used During Training: 2.85952 MB\n"
     ]
    }
   ],
   "source": [
    "# After the training loop, to record the final memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    # Calculate the peak memory usage during the training\n",
    "    peak_memory = torch.cuda.max_memory_allocated()\n",
    "    # Calculate the final memory usage after training\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "\n",
    " # Calculate the memory used during the training\n",
    "    memory_used = final_memory - initial_memory\n",
    "\n",
    "    # Reset memory stats for future measurements\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    print(f\"Peak Memory Allocated During Training: {peak_memory / 1e6} MB\")\n",
    "    print(f\"Final Memory Allocated: {final_memory / 1e6} MB\")\n",
    "    # Adding the new line here to show memory used\n",
    "    print(f\"Memory Used During Training: {memory_used / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "error",
     "timestamp": 1734214964581,
     "user": {
      "displayName": "Judy12",
      "userId": "10185014653289266631"
     },
     "user_tz": -600
    },
    "id": "S6MZj-Gyi6Bz",
    "outputId": "53c562ad-eac1-43a4-a060-3ef5b70d3d18"
   },
   "outputs": [],
   "source": [
    "# and it's been trained\n",
    "\n",
    "replacement_value = m\n",
    "\n",
    "# Dynamically construct the file name\n",
    "model_save_path = 'Early_fusionp$num$_trento_model_state_dict.pth'\n",
    "model_save_path = model_save_path.replace('$num$', str(replacement_value))\n",
    "\n",
    "# Save the model state dictionary to the updated path\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "dHZbaE95i6B0",
    "outputId": "6c4e3a45-a4fa-4248-9a2c-f6340eca305a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Early_fusionp1_trento_model_state_dict.pth\n",
      "Overall Accuracy (OA): 0.9239\n",
      "Average Accuracy (AA): 0.9324\n",
      "Kappa Coefficient: 0.8986\n",
      "Test time: 1.26 seconds\n",
      "Class 1 Accuracy: 0.8428\n",
      "Class 2 Accuracy: 0.9611\n",
      "Class 3 Accuracy: 0.9786\n",
      "Class 4 Accuracy: 0.9969\n",
      "Class 5 Accuracy: 0.8741\n",
      "Class 6 Accuracy: 0.9410\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "# import time  # Import the time module for timing the test phase\n",
    "\n",
    "# Save the model\n",
    "#model_save_path =  'Early_fusionp$num$_trento_model_state_dict.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "#replacement_value = m  # Replace \"m\" with this number dynamically\n",
    "\n",
    "# Replace \"$m$\" with the integer value\n",
    "#model_save_path = model_save_path.replace('$num$', str(replacement_value))\n",
    "\n",
    "\n",
    "print(f'Model saved to {model_save_path}')\n",
    "\n",
    "# Load the model (make sure to initialize the model architecture first)\n",
    "model.load_state_dict(torch.load(model_save_path,weights_only=False))\n",
    "model.to(device)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Store predictions and actual labels\n",
    "predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "with torch.no_grad():\n",
    "    for hsi_patches, labels in test_loader:\n",
    "        # Move data to the appropriate device\n",
    "        hsi_patches = hsi_patches.to(device)\n",
    "        labels -= 1  # Adjust labels if necessary\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(hsi_patches)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "end_time = time.time()  # End timing\n",
    "test_time = end_time - start_time  # Calculate the test time\n",
    "\n",
    "# Optionally, calculate accuracy or other metrics using predictions and actual_labels\n",
    "\n",
    "# Convert lists to NumPy arrays for easier manipulation\n",
    "predictions_array = np.array(predictions)\n",
    "actual_labels_array = np.array(actual_labels)\n",
    "\n",
    "# Overall Accuracy\n",
    "oa = accuracy_score(actual_labels_array, predictions_array)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(actual_labels_array, predictions_array)\n",
    "# Calculate per-class accuracy from the confusion matrix\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "# Average Accuracy\n",
    "aa = np.mean(class_accuracy)\n",
    "\n",
    "# Kappa Coefficient\n",
    "kappa = cohen_kappa_score(actual_labels_array, predictions_array)\n",
    "\n",
    "print(f'Overall Accuracy (OA): {oa:.4f}')\n",
    "print(f'Average Accuracy (AA): {aa:.4f}')\n",
    "print(f'Kappa Coefficient: {kappa:.4f}')\n",
    "print(f'Test time: {test_time:.2f} seconds')  # Print the test time\n",
    "\n",
    "for i, acc in enumerate(class_accuracy): print(f'Class {i+1} Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Reversed stream Data code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P1\n",
    "Finished training. Total training time: 67.36 seconds\n",
    "Model saved to Early_fusionp1_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9239\n",
    "Average Accuracy (AA): 0.9324\n",
    "Kappa Coefficient: 0.8986\n",
    "Test time: 1.26 seconds\n",
    "Class 1 Accuracy: 0.8428\n",
    "Class 2 Accuracy: 0.9611\n",
    "Class 3 Accuracy: 0.9786\n",
    "Class 4 Accuracy: 0.9969\n",
    "Class 5 Accuracy: 0.8741\n",
    "Class 6 Accuracy: 0.9410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P3\n",
    "Finished training. Total training time: 61.64 seconds\n",
    "    Model saved to Early_fusionp3_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9878\n",
    "Average Accuracy (AA): 0.9876\n",
    "Kappa Coefficient: 0.9836\n",
    "Test time: 1.78 seconds\n",
    "Class 1 Accuracy: 0.9880\n",
    "Class 2 Accuracy: 0.9741\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9994\n",
    "Class 5 Accuracy: 0.9826\n",
    "Class 6 Accuracy: 0.9817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P5\n",
    "Finished training. Total training time: 69.50 seconds\n",
    "Model saved to Early_fusionp5_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9949\n",
    "Average Accuracy (AA): 0.9922\n",
    "Kappa Coefficient: 0.9932\n",
    "Test time: 1.89 seconds\n",
    "Class 1 Accuracy: 0.9936\n",
    "Class 2 Accuracy: 0.9712\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9999\n",
    "Class 5 Accuracy: 0.9989\n",
    "Class 6 Accuracy: 0.9895\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P7\n",
    "Finished training. Total training time: 93.78 seconds\n",
    "    Model saved to Early_fusionp7_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9939\n",
    "Average Accuracy (AA): 0.9904\n",
    "Kappa Coefficient: 0.9919\n",
    "Test time: 2.65 seconds\n",
    "Class 1 Accuracy: 0.9895\n",
    "Class 2 Accuracy: 0.9748\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9999\n",
    "Class 6 Accuracy: 0.9784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P9\n",
    "Finished training. Total training time: 124.16 seconds\n",
    "    Model saved to Early_fusionp9_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9962\n",
    "Average Accuracy (AA): 0.9943\n",
    "Kappa Coefficient: 0.9949\n",
    "Test time: 3.53 seconds\n",
    "Class 1 Accuracy: 0.9887\n",
    "Class 2 Accuracy: 0.9874\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9999\n",
    "Class 6 Accuracy: 0.9898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch=11 epoch=100\n",
    "Finished training. Total training time: 165.42 seconds\n",
    "Model saved to Early_fusionp11_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9972\n",
    "Average Accuracy (AA): 0.9953\n",
    "Kappa Coefficient: 0.9962\n",
    "Test time: 4.51 seconds\n",
    "Class 1 Accuracy: 0.9926\n",
    "Class 2 Accuracy: 0.9921\n",
    "Class 3 Accuracy: 0.9973\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 0.9898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P13\n",
    "Finished training. Total training time: 217.60 seconds\n",
    "Model saved to Early_fusionp13_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9968\n",
    "Average Accuracy (AA): 0.9954\n",
    "Kappa Coefficient: 0.9958\n",
    "Test time: 5.84 seconds\n",
    "Class 1 Accuracy: 0.9928\n",
    "Class 2 Accuracy: 0.9946\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9994\n",
    "Class 6 Accuracy: 0.9856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P15\n",
    "Finished training. Total training time: 250.93 seconds\n",
    "    Model saved to Early_fusionp15_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9950\n",
    "Average Accuracy (AA): 0.9918\n",
    "Kappa Coefficient: 0.9933\n",
    "Test time: 8.05 seconds\n",
    "Class 1 Accuracy: 0.9936\n",
    "Class 2 Accuracy: 0.9971\n",
    "Class 3 Accuracy: 0.9973\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 0.9626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P17\n",
    "Finished training. Total training time: 296.55 seconds\n",
    "    Model saved to Early_fusionp17_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9958\n",
    "Average Accuracy (AA): 0.9929\n",
    "Kappa Coefficient: 0.9944\n",
    "Test time: 9.18 seconds\n",
    "Class 1 Accuracy: 0.9969\n",
    "Class 2 Accuracy: 0.9827\n",
    "Class 3 Accuracy: 0.9973\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9999\n",
    "Class 6 Accuracy: 0.9803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Reversed Data code , No need to normalistion based on P9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch=11 epoch=100 Normalisation \n",
    "Finished training. Total training time: 166.28 seconds\n",
    "    Memory Used During Training: 0.246272 MB\n",
    "Model saved to Early_fusionp11_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9972\n",
    "Average Accuracy (AA): 0.9957\n",
    "Kappa Coefficient: 0.9962\n",
    "Test time: 4.52 seconds\n",
    "Class 1 Accuracy: 0.9918\n",
    "Class 2 Accuracy: 0.9910\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 1.0000\n",
    "Class 6 Accuracy: 0.9915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Normalisation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 124.35 seconds\n",
    "Model saved to Early_fusionp1_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9378\n",
    "Average Accuracy (AA): 0.9440\n",
    "Kappa Coefficient: 0.9172\n",
    "Test time: 1.65 seconds\n",
    "Class 1 Accuracy: 0.8932\n",
    "Class 2 Accuracy: 0.9741\n",
    "Class 3 Accuracy: 0.9706\n",
    "Class 4 Accuracy: 0.9965\n",
    "Class 5 Accuracy: 0.8930\n",
    "Class 6 Accuracy: 0.9368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 100.57 seconds\n",
    "Model saved to Early_fusionp3_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9890\n",
    "Average Accuracy (AA): 0.9833\n",
    "Kappa Coefficient: 0.9852\n",
    "Test time: 1.68 seconds\n",
    "Class 1 Accuracy: 0.9813\n",
    "Class 2 Accuracy: 0.9615\n",
    "Class 3 Accuracy: 0.9866\n",
    "Class 4 Accuracy: 0.9978\n",
    "Class 5 Accuracy: 0.9951\n",
    "Class 6 Accuracy: 0.9777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 49.65 seconds\n",
    "Model saved to Early_fusionp5_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9902\n",
    "Average Accuracy (AA): 0.9828\n",
    "Kappa Coefficient: 0.9868\n",
    "Test time: 1.73 seconds\n",
    "Class 1 Accuracy: 0.9777\n",
    "Class 2 Accuracy: 0.9536\n",
    "Class 3 Accuracy: 0.9866\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9995\n",
    "Class 6 Accuracy: 0.9794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 76.70 seconds\n",
    "Model saved to Early_fusionp7_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9904\n",
    "Average Accuracy (AA): 0.9842\n",
    "Kappa Coefficient: 0.9871\n",
    "Test time: 1.82 seconds\n",
    "Class 1 Accuracy: 0.9862\n",
    "Class 2 Accuracy: 0.9683\n",
    "Class 3 Accuracy: 0.9920\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9984\n",
    "Class 6 Accuracy: 0.9604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 53.48 seconds\n",
    "Model saved to Early_fusionp9_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9902\n",
    "Average Accuracy (AA): 0.9849\n",
    "Kappa Coefficient: 0.9869\n",
    "Test time: 2.08 seconds\n",
    "Class 1 Accuracy: 0.9844\n",
    "Class 2 Accuracy: 0.9662\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9989\n",
    "Class 6 Accuracy: 0.9600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 68.32 seconds\n",
    "Model saved to Early_fusionp11_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9932\n",
    "Average Accuracy (AA): 0.9872\n",
    "Kappa Coefficient: 0.9909\n",
    "Test time: 2.28 seconds\n",
    "Class 1 Accuracy: 0.9944\n",
    "Class 2 Accuracy: 0.9816\n",
    "Class 3 Accuracy: 0.9866\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9999\n",
    "Class 6 Accuracy: 0.9607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finished training. Total training time: 80.24 seconds\n",
    "Model saved to Early_fusionp13_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9905\n",
    "Average Accuracy (AA): 0.9852\n",
    "Kappa Coefficient: 0.9872\n",
    "Test time: 2.46 seconds\n",
    "Class 1 Accuracy: 0.9992\n",
    "Class 2 Accuracy: 0.9845\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 1.0000\n",
    "Class 5 Accuracy: 0.9983\n",
    "Class 6 Accuracy: 0.9292"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtMdhUOKi6B0"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 152.45 seconds\n",
    "Model saved to Early_fusionp1_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.8520\n",
    "Average Accuracy (AA): 0.8663\n",
    "Kappa Coefficient: 0.8032\n",
    "Test time: 1.71 seconds\n",
    "Class 1 Accuracy: 0.8796\n",
    "Class 2 Accuracy: 0.8078\n",
    "Class 3 Accuracy: 0.9920\n",
    "Class 4 Accuracy: 0.8794\n",
    "Class 5 Accuracy: 0.8407\n",
    "Class 6 Accuracy: 0.7982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB_KWmgWi6B0"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 155.26 seconds\n",
    "Model saved to Early_fusionp13_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9719\n",
    "Average Accuracy (AA): 0.9615\n",
    "Kappa Coefficient: 0.9623\n",
    "Test time: 2.40 seconds\n",
    "Class 1 Accuracy: 0.9949\n",
    "Class 2 Accuracy: 0.8834\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9767\n",
    "Class 5 Accuracy: 0.9984\n",
    "Class 6 Accuracy: 0.9158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZ-tGREvi6B0"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 105.63 seconds\n",
    "Model saved to Early_fusionp11_Uh2013_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9751\n",
    "Average Accuracy (AA): 0.9594\n",
    "Kappa Coefficient: 0.9666\n",
    "Test time: 2.27 seconds\n",
    "Class 1 Accuracy: 0.9918\n",
    "Class 2 Accuracy: 0.8949\n",
    "Class 3 Accuracy: 0.9786\n",
    "Class 4 Accuracy: 0.9935\n",
    "Class 5 Accuracy: 0.9960\n",
    "Class 6 Accuracy: 0.9014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmBhfZ5-i6B0"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 135.61 seconds\n",
    "Model saved to Early_fusionp9_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9701\n",
    "Average Accuracy (AA): 0.9580\n",
    "Kappa Coefficient: 0.9600\n",
    "Test time: 2.11 seconds\n",
    "Class 1 Accuracy: 0.9867\n",
    "Class 2 Accuracy: 0.9039\n",
    "Class 3 Accuracy: 0.9920\n",
    "Class 4 Accuracy: 0.9988\n",
    "Class 5 Accuracy: 0.9810\n",
    "Class 6 Accuracy: 0.8856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERexNq1Yi6B1"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 95.08 seconds\n",
    "Model saved to Early_fusionp7_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9701\n",
    "Average Accuracy (AA): 0.9577\n",
    "Kappa Coefficient: 0.9599\n",
    "Test time: 1.81 seconds\n",
    "Class 1 Accuracy: 0.9931\n",
    "Class 2 Accuracy: 0.8970\n",
    "Class 3 Accuracy: 0.9947\n",
    "Class 4 Accuracy: 0.9916\n",
    "Class 5 Accuracy: 0.9873\n",
    "Class 6 Accuracy: 0.8827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLBfIWb2i6B1"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 136.45 seconds\n",
    "Model saved to Early_fusionp5_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9620\n",
    "Average Accuracy (AA): 0.9534\n",
    "Kappa Coefficient: 0.9492\n",
    "Test time: 1.73 seconds\n",
    "Class 1 Accuracy: 0.9949\n",
    "Class 2 Accuracy: 0.9010\n",
    "Class 3 Accuracy: 0.9893\n",
    "Class 4 Accuracy: 0.9831\n",
    "Class 5 Accuracy: 0.9704\n",
    "Class 6 Accuracy: 0.8817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbTDzr0Ai6B1"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 156.99 seconds\n",
    "Model saved to Early_fusionp3_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9163\n",
    "Average Accuracy (AA): 0.9095\n",
    "Kappa Coefficient: 0.8873\n",
    "Test time: 1.67 seconds\n",
    "Class 1 Accuracy: 0.9357\n",
    "Class 2 Accuracy: 0.8909\n",
    "Class 3 Accuracy: 0.9893\n",
    "Class 4 Accuracy: 0.8675\n",
    "Class 5 Accuracy: 0.9968\n",
    "Class 6 Accuracy: 0.7769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qsa83_di6B1"
   },
   "source": [
    "# 5.2 Trainingfor HSI+Lidar in Middle Features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMd0SiESi6B1"
   },
   "outputs": [],
   "source": [
    "# Before the training loop, to record the initial memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset peak memory stats at the start\n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    print(f\"Initial Memory Allocated: {initial_memory / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pj1DdHLNi6B2",
    "outputId": "e7d99178-7d94-42a9-e7cc-80b51fd9d437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Train Loss: 1.6277, Val Loss: 1.4540\n",
      "Validation Loss Decreased(inf--->1.454028) \t Saving The Model\n",
      "Epoch [2/300], Train Loss: 1.4245, Val Loss: 1.3210\n",
      "Validation Loss Decreased(1.454028--->1.320959) \t Saving The Model\n",
      "Epoch [3/300], Train Loss: 1.2968, Val Loss: 1.1950\n",
      "Validation Loss Decreased(1.320959--->1.195024) \t Saving The Model\n",
      "Epoch [4/300], Train Loss: 1.1756, Val Loss: 1.0925\n",
      "Validation Loss Decreased(1.195024--->1.092517) \t Saving The Model\n",
      "Epoch [5/300], Train Loss: 1.0720, Val Loss: 0.9860\n",
      "Validation Loss Decreased(1.092517--->0.985964) \t Saving The Model\n",
      "Epoch [6/300], Train Loss: 0.9758, Val Loss: 0.8880\n",
      "Validation Loss Decreased(0.985964--->0.887956) \t Saving The Model\n",
      "Epoch [7/300], Train Loss: 0.8845, Val Loss: 0.8059\n",
      "Validation Loss Decreased(0.887956--->0.805907) \t Saving The Model\n",
      "Epoch [8/300], Train Loss: 0.8086, Val Loss: 0.7259\n",
      "Validation Loss Decreased(0.805907--->0.725859) \t Saving The Model\n",
      "Epoch [9/300], Train Loss: 0.7256, Val Loss: 0.6590\n",
      "Validation Loss Decreased(0.725859--->0.659045) \t Saving The Model\n",
      "Epoch [10/300], Train Loss: 0.6600, Val Loss: 0.6056\n",
      "Validation Loss Decreased(0.659045--->0.605625) \t Saving The Model\n",
      "Epoch [11/300], Train Loss: 0.6014, Val Loss: 0.5485\n",
      "Validation Loss Decreased(0.605625--->0.548519) \t Saving The Model\n",
      "Epoch [12/300], Train Loss: 0.5481, Val Loss: 0.5089\n",
      "Validation Loss Decreased(0.548519--->0.508862) \t Saving The Model\n",
      "Epoch [13/300], Train Loss: 0.5092, Val Loss: 0.4611\n",
      "Validation Loss Decreased(0.508862--->0.461126) \t Saving The Model\n"
     ]
    }
   ],
   "source": [
    "# # 2.0 HSI+Lidar\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import copy\n",
    "# import time  # Step 1: Import the time module\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = HSILidClassificationMambaModel(\n",
    "    spatial_dim=m,\n",
    "    hsi_num_bands=63,\n",
    "    lidar_num_bands=1,\n",
    "    hidden_dim=1024,\n",
    "    output_dim=512,\n",
    "    delta_param_init=0.1,\n",
    "    num_classes=6\n",
    ")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "\n",
    "epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "patience = 50\n",
    "\n",
    "start_time = time.time()  # Step 2: Record the start time\n",
    "# Updated Training Loop with HSI and LiDAR data\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for (hsi_inputs, labels), (lidar_inputs, _) in zip(hsi_train_loader, Lidar_train_loader):\n",
    "        hsi_inputs = hsi_inputs.to(device)\n",
    "        lidar_inputs = lidar_inputs.to(device)\n",
    "        labels -= 1\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(hsi_inputs, lidar_inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item() * hsi_inputs.size(0)\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(hsi_train_loader.dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for (hsi_inputs, labels), (lidar_inputs, _) in zip(hsi_val_loader, Lidar_val_loader):\n",
    "            hsi_inputs = hsi_inputs.to(device)\n",
    "            lidar_inputs = lidar_inputs.to(device)\n",
    "            labels -= 1\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(hsi_inputs, lidar_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * hsi_inputs.size(0)\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(hsi_val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "    # Check if this is the best model (based on validation loss)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        print(f'Validation Loss Decreased({best_val_loss:.6f}--->{epoch_val_loss:.6f}) \\t Saving The Model')\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if no_improve_epochs > patience:\n",
    "        print('Early stopping!')\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_wts)  # Load best model weights\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "total_time = end_time - start_time  # Calculate total training time\n",
    "print(f'Finished training. Total training time: {total_time:.2f} seconds')  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yN7gHcci6B2"
   },
   "outputs": [],
   "source": [
    "# After the training loop, to record the final memory usage (GPU)\n",
    "if torch.cuda.is_available():\n",
    "    # Calculate the peak memory usage during the training\n",
    "    peak_memory = torch.cuda.max_memory_allocated()\n",
    "    # Calculate the final memory usage after training\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "\n",
    "    # Calculate the memory used during the training\n",
    "    memory_used = final_memory - initial_memory\n",
    "\n",
    "    # Reset memory stats for future measurements\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    print(f\"Peak Memory Allocated During Training: {peak_memory / 1e6} MB\")\n",
    "    print(f\"Final Memory Allocated: {final_memory / 1e6} MB\")\n",
    "    # Adding the new line here to show memory used\n",
    "    print(f\"Memory Used During Training: {memory_used / 1e6} MB\")# After the training loop, to record the final memory usage (GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9v9pKBZi6B2"
   },
   "outputs": [],
   "source": [
    "\n",
    "replacement = m\n",
    "\n",
    "# Dynamically construct the file name\n",
    "model_save_path = 'mid_fusionp$num$_trento_model_state_dict.pth'\n",
    "model_save_path = model_save_path.replace('$num$', str(replacement))\n",
    "\n",
    "# Save the model state dictionary to the updated path\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFn9NhWTi6B2"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "# import time\n",
    "\n",
    "#model_save_path =  'mid_fusionp$num$_trento_model_state_dict.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "#replacement_value = m  # Replace \"m\" with this number dynamically\n",
    "\n",
    "# Replace \"$m$\" with the integer value\n",
    "#model_save_path = model_save_path.replace('$num$', str(replacement_value))\n",
    "print(f'Model saved to {model_save_path}')\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(model_save_path,weights_only=False))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "predictions = []\n",
    "actual_labels = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (hsi_patches, hsi_labels), (lidar_patches, _) in zip(hsi_test_loader, Lidar_test_loader):\n",
    "        hsi_patches = hsi_patches.to(device)\n",
    "        lidar_patches = lidar_patches.to(device)\n",
    "        hsi_labels -= 1\n",
    "        hsi_labels = hsi_labels.to(device)\n",
    "\n",
    "        # Forward pass using both HSI and LiDAR patches\n",
    "        outputs = model(hsi_patches, lidar_patches)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        actual_labels.extend(hsi_labels.cpu().numpy())\n",
    "\n",
    "end_time = time.time()\n",
    "test_time = end_time - start_time\n",
    "\n",
    "# Convert lists to NumPy arrays for calculation\n",
    "predictions_array = np.array(predictions)\n",
    "actual_labels_array = np.array(actual_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "oa = accuracy_score(actual_labels_array, predictions_array)\n",
    "cm = confusion_matrix(actual_labels_array, predictions_array)\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = np.mean(class_accuracy)\n",
    "kappa = cohen_kappa_score(actual_labels_array, predictions_array)\n",
    "\n",
    "print(f'Overall Accuracy (OA): {oa:.4f}')\n",
    "print(f'Average Accuracy (AA): {aa:.4f}')\n",
    "print(f'Kappa Coefficient: {kappa:.4f}')\n",
    "print(f'Test time: {test_time:.2f} seconds')\n",
    "\n",
    "for i, acc in enumerate(class_accuracy): print(f'Class {i+1} Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waIOycIEi6B3"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 213.02 seconds\n",
    "Model saved to mid_fusionp1_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.8557\n",
    "Average Accuracy (AA): 0.8688\n",
    "Kappa Coefficient: 0.8079\n",
    "Test time: 2.38 seconds\n",
    "Class 1 Accuracy: 0.8873\n",
    "Class 2 Accuracy: 0.8143\n",
    "Class 3 Accuracy: 0.9866\n",
    "Class 4 Accuracy: 0.8961\n",
    "Class 5 Accuracy: 0.8330\n",
    "Class 6 Accuracy: 0.7952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLKCtkRei6B3"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 142.33 seconds\n",
    "Model saved to mid_fusionp13_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9783\n",
    "Average Accuracy (AA): 0.9680\n",
    "Kappa Coefficient: 0.9709\n",
    "Test time: 3.28 seconds\n",
    "Class 1 Accuracy: 0.9839\n",
    "Class 2 Accuracy: 0.9172\n",
    "Class 3 Accuracy: 0.9973\n",
    "Class 4 Accuracy: 0.9957\n",
    "Class 5 Accuracy: 0.9944\n",
    "Class 6 Accuracy: 0.9194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcuCNjw3i6B3"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 91.29 seconds\n",
    "Model saved to mid_fusionp11_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9733\n",
    "Average Accuracy (AA): 0.9631\n",
    "Kappa Coefficient: 0.9642\n",
    "Test time: 3.08 seconds\n",
    "Class 1 Accuracy: 0.9752\n",
    "Class 2 Accuracy: 0.9172\n",
    "Class 3 Accuracy: 0.9866\n",
    "Class 4 Accuracy: 0.9787\n",
    "Class 5 Accuracy: 0.9973\n",
    "Class 6 Accuracy: 0.9233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqGXnyC8i6B3"
   },
   "outputs": [],
   "source": [
    "\n",
    "Finished training. Total training time: 209.29 seconds\n",
    "Model saved to Early_fusionp9_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9734\n",
    "Average Accuracy (AA): 0.9623\n",
    "Kappa Coefficient: 0.9643\n",
    "Test time: 2.87 seconds\n",
    "Class 1 Accuracy: 0.9859\n",
    "Class 2 Accuracy: 0.8920\n",
    "Class 3 Accuracy: 0.9947\n",
    "Class 4 Accuracy: 0.9812\n",
    "Class 5 Accuracy: 0.9983\n",
    "Class 6 Accuracy: 0.9220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95hrYtuRi6B4"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 107.16 seconds\n",
    "Model saved to mid_fusionp7_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9710\n",
    "Average Accuracy (AA): 0.9607\n",
    "Kappa Coefficient: 0.9612\n",
    "Test time: 2.62 seconds\n",
    "Class 1 Accuracy: 0.9844\n",
    "Class 2 Accuracy: 0.8787\n",
    "Class 3 Accuracy: 1.0000\n",
    "Class 4 Accuracy: 0.9816\n",
    "Class 5 Accuracy: 0.9941\n",
    "Class 6 Accuracy: 0.9256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GabiUmwRi6B4"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 118.57 seconds\n",
    "Model saved to mid_fusionp5_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9636\n",
    "Average Accuracy (AA): 0.9500\n",
    "Kappa Coefficient: 0.9512\n",
    "Test time: 2.52 seconds\n",
    "Class 1 Accuracy: 0.9836\n",
    "Class 2 Accuracy: 0.8589\n",
    "Class 3 Accuracy: 0.9866\n",
    "Class 4 Accuracy: 0.9777\n",
    "Class 5 Accuracy: 0.9887\n",
    "Class 6 Accuracy: 0.9047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KxP_2d9i6B4"
   },
   "outputs": [],
   "source": [
    "Finished training. Total training time: 217.86 seconds\n",
    "Model saved to mid_fusionp3_trento_model_state_dict.pth\n",
    "Overall Accuracy (OA): 0.9502\n",
    "Average Accuracy (AA): 0.9472\n",
    "Kappa Coefficient: 0.9333\n",
    "Test time: 2.43 seconds\n",
    "Class 1 Accuracy: 0.9898\n",
    "Class 2 Accuracy: 0.8549\n",
    "Class 3 Accuracy: 0.9947\n",
    "Class 4 Accuracy: 0.9702\n",
    "Class 5 Accuracy: 0.9495\n",
    "Class 6 Accuracy: 0.9243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmo7qTuei6B4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lw61seAVi6B4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcd8hjl5i6B4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J95ziYowi6B5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCEDrZOyi6B5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCqAa0cci6B5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcRUYiWIWlz-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": [
    {
     "file_id": "1vdJ_og-9a0BNRBZE0hTdttrwRQPEhjSh",
     "timestamp": 1729546157083
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
